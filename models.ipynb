{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T14:35:32.590479Z",
     "iopub.status.busy": "2020-11-05T14:35:32.589478Z",
     "iopub.status.idle": "2020-11-05T14:35:32.600476Z",
     "shell.execute_reply": "2020-11-05T14:35:32.600476Z",
     "shell.execute_reply.started": "2020-11-05T14:35:32.590479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "Tensorflow Version: 2.4.0-rc0\n",
      "Numpy Version: 1.19.2\n",
      "Matplotlib Version: 3.3.1\n",
      "Keras Version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from os import listdir, mkdir\n",
    "from os.path import splitext\n",
    "from os.path import join\n",
    "from skimage import io, color\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check if Tensorflow uses GPU\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Limit GPU memory usage\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "print()\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "# print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"Matplotlib Version: {matplotlib.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T14:35:47.765968Z",
     "iopub.status.busy": "2020-11-05T14:35:47.764967Z",
     "iopub.status.idle": "2020-11-05T14:36:00.392964Z",
     "shell.execute_reply": "2020-11-05T14:36:00.392964Z",
     "shell.execute_reply.started": "2020-11-05T14:35:47.765968Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = scipy.sparse.load_npz('data/train_features.npz')\n",
    "val_features = scipy.sparse.load_npz(\"data/val_features.npz\")\n",
    "train_labels = np.load(\"data/train_labels.npy\")\n",
    "val_labels = np.load(\"data/val_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the .npz and .npy files for training and validation set\n",
    "2. The features are starting from Class 0 till Class 7 in Ascending order\n",
    "3. For each class, take all features of each video, take this as sequence\n",
    "    3.1 Look up what the largest sequence length is\n",
    "    3.2 Pad all other sequences to the largest sequence length\n",
    "4. Reshape the features to [sequences, sequence_length, features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T14:49:39.545616Z",
     "iopub.status.busy": "2020-11-05T14:49:39.545616Z",
     "iopub.status.idle": "2020-11-05T14:49:39.554615Z",
     "shell.execute_reply": "2020-11-05T14:49:39.554615Z",
     "shell.execute_reply.started": "2020-11-05T14:49:39.545616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup up model with base_VGG19 and all those layers frozen\n",
    "# Define the sequence input size\n",
    "\n",
    "def build_model(inp_shape):\n",
    "    model = Sequential(name=\"RNN-LSTM\")\n",
    "    model.add(layers.LSTM(16, input_shape=inp_shape, return_sequences=True, dropout=0.5, name=\"LSTM_1\"))\n",
    "    model.add(layers.Dense(7, activation=\"softmax\", name=\"Dense_Output\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T14:49:09.689249Z",
     "iopub.status.busy": "2020-11-05T14:49:09.689249Z",
     "iopub.status.idle": "2020-11-05T14:49:09.912873Z",
     "shell.execute_reply": "2020-11-05T14:49:09.912873Z",
     "shell.execute_reply.started": "2020-11-05T14:49:09.689249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN-LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (LSTM)                (None, 1, 16)             1152      \n",
      "_________________________________________________________________\n",
      "Dense_Output (Dense)         (None, 1, 7)              119       \n",
      "=================================================================\n",
      "Total params: 1,271\n",
      "Trainable params: 1,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_rnn_LSTM = build_model((1,1))\n",
    "cnn_rnn_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AW2_norm_minitrain = AW2_norm_minitrain.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "history = cnn_rnn_LSTM.fit(\n",
    "    AW2_norm_train.batch(32, drop_remainder=True),\n",
    "    validation_data=AW2_norm_val.batch(32, drop_remainder=True),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_rnn_LSTM.evaluate(AW2_norm_train.batch(8, drop_remainder=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
