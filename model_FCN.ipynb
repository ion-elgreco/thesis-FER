{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Limit GPU memory usage\n",
    "for device in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Aff-Wild2 Features\n",
    "X_train = scipy.sparse.load_npz(\"data/features/train_features_RGB_AW2.npz\") #CSR Matrix\n",
    "X_val = scipy.sparse.load_npz(\"data/features/val_features_RGB_AW2.npz\") #CSR Matrix\n",
    "y_train = np.load(\"data/labels/train_labels_RGB_AW2.npy\") #Numpy array\n",
    "y_val = np.load(\"data/labels/val_labels_RGB_AW2.npy\") #Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AFEW7.0 features\n",
    "X_test_AF7 = scipy.sparse.load_npz(\"data/features/features_RGB_AF7.npz\") #CSR Matrix\n",
    "y_test_AF7 = np.load(\"data/labels/labels_RGB_AF7.npy\") #Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the validation set into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, random_state = 1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4 5 6], y=[0 0 0 ... 6 6 6] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_label_ints = np.argmax(y_train, axis=1) \n",
    "class_weights = class_weight.compute_class_weight(\n",
    "        \"balanced\", np.unique(train_label_ints), train_label_ints.flatten()\n",
    "    )\n",
    "class_weights = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"weights.json\", 'w') as fp:\n",
    "    json.dump(class_weights, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0025,\n",
    "    patience=6,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "Dense_Output (Dense)         (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 147,719\n",
      "Trainable params: 147,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1801/1801 [==============================] - 17s 9ms/step - loss: 2.6186 - accuracy: 0.6183 - val_loss: 3.6355 - val_accuracy: 0.3608\n",
      "Epoch 2/5\n",
      "1801/1801 [==============================] - 16s 8ms/step - loss: 0.4474 - accuracy: 0.7599 - val_loss: 3.0565 - val_accuracy: 0.3730\n",
      "Epoch 3/5\n",
      "1801/1801 [==============================] - 15s 8ms/step - loss: 0.4136 - accuracy: 0.7683 - val_loss: 3.1195 - val_accuracy: 0.3904\n",
      "Epoch 4/5\n",
      "1801/1801 [==============================] - 14s 7ms/step - loss: 0.4052 - accuracy: 0.7709 - val_loss: 3.0134 - val_accuracy: 0.4206\n",
      "Epoch 5/5\n",
      "1801/1801 [==============================] - 13s 6ms/step - loss: 0.3916 - accuracy: 0.7753 - val_loss: 3.0731 - val_accuracy: 0.4066\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.InputLayer(input_shape=4608,))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Dense(7, activation=\"softmax\", name=\"Dense_Output\"))\n",
    "model.compile(optimizer=\"adam\", loss=CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "# Fit model to training set and evaluate\n",
    "batchsize = 512\n",
    "history = model.fit(\n",
    "    train_features_AW2,\n",
    "    train_labels_AW2,\n",
    "    batch_size=batchsize,\n",
    "    class_weight=class_weights,\n",
    "    validation_data=(val_features_AW2, val_labels_AW2),\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Save model\n",
    "tf.keras.Model.save(\n",
    "    model,\n",
    "    filepath=f\"data/models/models_with_extractedfeatures_vgg19block5/FCN.h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T14:53:14.852248Z",
     "iopub.status.busy": "2020-11-30T14:53:14.852248Z",
     "iopub.status.idle": "2020-11-30T14:53:14.862246Z",
     "shell.execute_reply": "2020-11-30T14:53:14.862246Z",
     "shell.execute_reply.started": "2020-11-30T14:53:14.852248Z"
    }
   },
   "source": [
    "## Evaluate on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "Dense_Output (Dense)         (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 147,719\n",
      "Trainable params: 147,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 3.0780 - accuracy: 0.4067\n",
      "{None: [0.5747922785350302, 0.04759898904802022, 0.010303967027305513, 0.05227369315767106, 0.34970800412229475, 0.1168451801363194, 0.2569468505301088], 'macro': 0.20120985179382142}\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 4.4993 - accuracy: 0.2175\n",
      "{None: [0.31015295287761085, 0.12989771393438043, 0.049733231707317076, 0.05375914836992682, 0.31831638563521686, 0.17792163209258988, 0.08081945069788384], 'macro': 0.16008578790213224}\n"
     ]
    }
   ],
   "source": [
    "NN = tf.keras.models.load_model(\n",
    "    filepath=f\"data/models/models_with_extractedfeatures_vgg19block5/FCN.h5\",\n",
    "    compile=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Check model summary\n",
    "NN.summary()\n",
    "\n",
    "# Evaluate on test set of AW2 to get test scores\n",
    "csvlog_AW2_test = tf.keras.callbacks.CSVLogger(\n",
    "    f\"data/models/test_scores/FCN_AW2_test_scores.csv\",\n",
    "    separator=\",\",\n",
    "    append=False,\n",
    ")\n",
    "NN.evaluate(\n",
    "    X_test, y_test, batch_size=batchsize, callbacks=[csvlog_AW2_test],\n",
    ")\n",
    "\n",
    "# Get F1 scores for AW2 test set\n",
    "test_pred = NN.predict(X_test, verbose=0)\n",
    "\n",
    "# Convert one hot encoding to integers\n",
    "test_pred = np.argmax(test_pred, axis=1)\n",
    "\n",
    "# Reshape back to (frame, label)\n",
    "test_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "f1scores_test = {\n",
    "    avg: f1_score(test_pred, test_true, average=avg) for avg in [None, \"macro\"]\n",
    "}\n",
    "f1scores_test[None] = f1scores_test.get(None).tolist()\n",
    "print(f1scores_test)\n",
    "\n",
    "with open(\n",
    "    f\"data/models/test_scores/FCN_AW2_test_F1scores.json\", \"w\",\n",
    ") as fp:\n",
    "    json.dump(f1scores_test, fp)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# Evaluate on test set of AF7 to get test scores for cross-dataset performance\n",
    "csvlog_AF7 = tf.keras.callbacks.CSVLogger(\n",
    "    f\"data/models/test_scores/FCN_AF7_test_scores.csv\",\n",
    "    separator=\",\",\n",
    "    append=False,\n",
    ")\n",
    "NN.evaluate(\n",
    "    X_test_AF7, y_test_AF7, batch_size=batchsize, callbacks=[csvlog_AF7],\n",
    ")\n",
    "\n",
    "# Get F1 scores for AF7 test set\n",
    "test_pred = NN.predict(X_test_AF7, verbose=0)\n",
    "\n",
    "# Convert one hot encoding to integers\n",
    "test_pred = np.argmax(test_pred, axis=1)\n",
    "\n",
    "# Reshape back to (frame, label)\n",
    "test_true = np.argmax(y_test_AF7, axis=1)\n",
    "\n",
    "f1scores_test = {\n",
    "    avg: f1_score(test_pred, test_true, average=avg) for avg in [None, \"macro\"]\n",
    "}\n",
    "f1scores_test[None] = f1scores_test.get(None).tolist()\n",
    "print(f1scores_test)\n",
    "\n",
    "with open(\n",
    "    f\"data/models/test_scores/FCN_AF7_test_F1scores.json\", \"w\",\n",
    ") as fp:\n",
    "    json.dump(f1scores_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "output_auto_scroll": true,
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
