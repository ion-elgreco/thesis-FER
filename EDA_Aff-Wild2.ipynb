{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T18:03:00.139718Z",
     "iopub.status.busy": "2020-10-27T18:03:00.138717Z",
     "iopub.status.idle": "2020-10-27T18:03:00.238717Z",
     "shell.execute_reply": "2020-10-27T18:03:00.238717Z",
     "shell.execute_reply.started": "2020-10-27T18:03:00.139718Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from os.path import join\n",
    "\n",
    "import skvideo\n",
    "\n",
    "skvideo.setFFmpegPath(\n",
    "    r\"C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\Lib\\site-packages\\ffmpeg-4.3.1-2020-10-01-full_build\\bin\"\n",
    ")\n",
    "import skvideo.io\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of different datasets\n",
    "The Aff-Wild2 dataset is used for training, validation and testing. While the AFEW 7.0 dataset is only used for testing. \n",
    "\n",
    "#### Aff-Wild2\n",
    "In this dataset all videos are in one folder. Each video has a corresponding .txt file where each frame is annotated with the correspending facial expression class at that frame. In each video multiple emotions are displayed, thats why the annotation is per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:47:58.017017Z",
     "iopub.status.busy": "2020-10-27T15:47:58.017017Z",
     "iopub.status.idle": "2020-10-27T15:47:58.026018Z",
     "shell.execute_reply": "2020-10-27T15:47:58.026018Z",
     "shell.execute_reply.started": "2020-10-27T15:47:58.017017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aff-Wild2 = AW2\n",
    "# filenames = FN\n",
    "\n",
    "### Aff-wild2 ###\n",
    "# Directories for labels/annotations for each set\n",
    "AW2_dir_train_labels = (\n",
    "    r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Videos\\annotations\\EXPR_Set\\Training_Set\"\n",
    ")\n",
    "AW2_dir_val_labels = (\n",
    "    r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Videos\\annotations\\EXPR_Set\\Validation_Set\"\n",
    ")\n",
    "\n",
    "# Directories for videos\n",
    "AW2_dir_allvideos = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Videos\\all_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:47:58.017017Z",
     "iopub.status.busy": "2020-10-27T15:47:58.017017Z",
     "iopub.status.idle": "2020-10-27T15:47:58.026018Z",
     "shell.execute_reply": "2020-10-27T15:47:58.026018Z",
     "shell.execute_reply.started": "2020-10-27T15:47:58.017017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the filenames in a list for each set, and split the filename from the extension\n",
    "AW2_train_FN = listdir(AW2_dir_train_labels)\n",
    "AW2_train_FN_split = [splitext(file) for file in AW2_train_FN]\n",
    "\n",
    "AW2_val_FN = listdir(AW2_dir_val_labels)\n",
    "AW2_val_FN_split = [splitext(file) for file in AW2_val_FN]\n",
    "\n",
    "AW2_videos_FN = listdir(AW2_dir_allvideos)\n",
    "AW2_videos_FN_split = [splitext(file) for file in AW2_videos_FN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aff-wild2 Dataset Size ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:47:59.953354Z",
     "iopub.status.busy": "2020-10-27T15:47:59.953354Z",
     "iopub.status.idle": "2020-10-27T15:47:59.972352Z",
     "shell.execute_reply": "2020-10-27T15:47:59.972352Z",
     "shell.execute_reply.started": "2020-10-27T15:47:59.953354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training-set contains: 253 videos\n",
      "The validation-set contains: 70 videos\n",
      "The test-set contains: 225 videos\n",
      "The whole dataset contains: 548 videos\n"
     ]
    }
   ],
   "source": [
    "# Size of each set\n",
    "print(f\"The training-set contains: {len(AW2_train_FN)} videos\")\n",
    "print(f\"The validation-set contains: {len(AW2_val_FN)} videos\")\n",
    "print(\n",
    "    f\"The test-set contains: {len(AW2_videos_FN) - (len(AW2_train_FN) + len(AW2_val_FN))} videos\"\n",
    ")\n",
    "print(f\"The whole dataset contains: {len(AW2_videos_FN)} videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:48:00.292909Z",
     "iopub.status.busy": "2020-10-27T15:48:00.292909Z",
     "iopub.status.idle": "2020-10-27T15:48:00.317907Z",
     "shell.execute_reply": "2020-10-27T15:48:00.317907Z",
     "shell.execute_reply.started": "2020-10-27T15:48:00.292909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "# Checking if the labeled filenames corresponds to the videos\n",
    "train_size = 0\n",
    "for i in AW2_train_FN_split:\n",
    "    for j in AW2_videos_FN_split:\n",
    "        if i[0] == j[0]:\n",
    "            train_size += 1\n",
    "\n",
    "## The results show that only 246 labels are matched to videos, while there were 253 labeled videos\n",
    "## Some videos contain two persons, so the labels are for one person on the left or right\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:48:02.328949Z",
     "iopub.status.busy": "2020-10-27T15:48:02.327946Z",
     "iopub.status.idle": "2020-10-27T15:48:02.362947Z",
     "shell.execute_reply": "2020-10-27T15:48:02.362947Z",
     "shell.execute_reply.started": "2020-10-27T15:48:02.328949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset is indeed = 253 videos\n",
      "Validation dataset is indeed = 70 videos\n"
     ]
    }
   ],
   "source": [
    "# Checking if the labeled filenames corresponds to the videos (and disregarding if its on left or right)\n",
    "train_size = 0\n",
    "for i in AW2_train_FN_split:\n",
    "    for j in AW2_videos_FN_split:\n",
    "        if \"_left\" in i[0]:\n",
    "            a = i[0].replace(\"_left\", \"\")\n",
    "        elif \"_right\" in i[0]:\n",
    "            a = i[0].replace(\"_right\", \"\")\n",
    "        else:\n",
    "            a = i[0]\n",
    "        if a == j[0]:\n",
    "            train_size += 1\n",
    "# Labels is equal to videos now\n",
    "print(f\"Training dataset is indeed = {train_size} videos\")\n",
    "\n",
    "# Checking if the labeled filenames corresponds to the videos (and disregarding if its on left or right)\n",
    "val_size = 0\n",
    "for i in AW2_val_FN_split:\n",
    "    for j in AW2_videos_FN_split:\n",
    "        if \"_left\" in i[0]:\n",
    "            a = i[0].replace(\"_left\", \"\")\n",
    "        elif \"_right\" in i[0]:\n",
    "            a = i[0].replace(\"_right\", \"\")\n",
    "        else:\n",
    "            a = i[0]\n",
    "        if a == j[0]:\n",
    "            val_size += 1\n",
    "# Labels is equal to videos now\n",
    "print(f\"Validation dataset is indeed = {val_size} videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence length of each video ###\n",
    "\n",
    "V1 and V2 use the metadata to retreive the amount of frames in each video. While fast, it can be inaccurate sometimes. Thats why I am using V3 to check the videos manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:07:07.071457Z",
     "iopub.status.busy": "2020-10-27T16:07:07.071457Z",
     "iopub.status.idle": "2020-10-27T16:07:32.350458Z",
     "shell.execute_reply": "2020-10-27T16:07:32.350458Z",
     "shell.execute_reply.started": "2020-10-27T16:07:07.071457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dictionary of sequence length of each video with ffprobe in skvideo\n",
    "AW2_seqlength = {}\n",
    "AW2_seqlength_without_extension = {}\n",
    "for video in AW2_videos_FN:\n",
    "    metadata = skvideo.io.ffprobe(join(AW2_dir_allvideos, video))\n",
    "    frames = int(metadata.get(\"video\").get(\"@nb_frames\"))\n",
    "    width = int(metadata.get(\"video\").get(\"@width\"))\n",
    "    height = int(metadata.get(\"video\").get(\"@height\"))\n",
    "    AW2_seqlength[video] = [frames, height, width, 3]\n",
    "\n",
    "    name, ext = splitext(video)\n",
    "    AW2_seqlength_without_extension[name] = [frames, height, width, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:11:15.452281Z",
     "iopub.status.busy": "2020-10-27T15:11:15.451282Z",
     "iopub.status.idle": "2020-10-27T15:11:15.456280Z",
     "shell.execute_reply": "2020-10-27T15:11:15.456280Z",
     "shell.execute_reply.started": "2020-10-27T15:11:15.452281Z"
    }
   },
   "source": [
    "##### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:48:38.872650Z",
     "iopub.status.busy": "2020-10-27T15:48:38.871649Z",
     "iopub.status.idle": "2020-10-27T15:49:07.297645Z",
     "shell.execute_reply": "2020-10-27T15:49:07.297645Z",
     "shell.execute_reply.started": "2020-10-27T15:48:38.872650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dictionary of sequence length of each video with ffprobe in skvideo and opencv to capture the amount of frames\n",
    "AW2_seqlength_V2 = {}\n",
    "\n",
    "for video in AW2_videos_FN:\n",
    "    metadata = skvideo.io.ffprobe(join(AW2_dir_allvideos, video))\n",
    "    width = int(metadata.get(\"video\").get(\"@width\"))\n",
    "    height = int(metadata.get(\"video\").get(\"@height\"))\n",
    "\n",
    "    cap = cv2.VideoCapture(join(AW2_dir_allvideos, video))\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    AW2_seqlength_V2[video] = [frames, height, width, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:49:07.299649Z",
     "iopub.status.busy": "2020-10-27T15:49:07.298647Z",
     "iopub.status.idle": "2020-10-27T15:49:07.314649Z",
     "shell.execute_reply": "2020-10-27T15:49:07.313650Z",
     "shell.execute_reply.started": "2020-10-27T15:49:07.299649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the video length is the same with each method\n",
    "AW2_seqlength == AW2_seqlength_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T13:27:42.781664Z",
     "iopub.status.busy": "2020-10-27T13:27:42.781664Z",
     "iopub.status.idle": "2020-10-27T15:02:00.807272Z",
     "shell.execute_reply": "2020-10-27T15:02:00.806271Z",
     "shell.execute_reply.started": "2020-10-27T13:27:42.781664Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of sequence length of each video with ffprobe in skvideo and opencv to capture the amount of frames manually\n",
    "AW2_seqlength_V3 = {}\n",
    "\n",
    "counter = 0\n",
    "for video in AW2_videos_FN:\n",
    "    print(counter)\n",
    "    counter += 1\n",
    "    metadata = skvideo.io.ffprobe(join(AW2_dir_allvideos, video))\n",
    "    width = int(metadata.get(\"video\").get(\"@width\"))\n",
    "    height = int(metadata.get(\"video\").get(\"@height\"))\n",
    "\n",
    "    frames = count_frames_manual(cv2.VideoCapture(join(AW2_dir_allvideos, video)))\n",
    "    AW2_seqlength_V3[video] = [frames, height, width, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:12:38.908103Z",
     "iopub.status.busy": "2020-10-27T15:12:38.908103Z",
     "iopub.status.idle": "2020-10-27T15:12:38.918103Z",
     "shell.execute_reply": "2020-10-27T15:12:38.918103Z",
     "shell.execute_reply.started": "2020-10-27T15:12:38.908103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the video length is the same between V1(=V2) and V3\n",
    "AW2_seqlength == AW2_seqlength_V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two videos seem to have less actual frames then the metadata has shown:\n",
    "\n",
    "- 252.mp4  \n",
    "    - V1: [2756, 360, 640, 3]\n",
    "    - V3: [2755, 360, 640, 3]\n",
    "- video30.mp4 \n",
    "    - V1: [8217, 1080, 1920, 3]\n",
    "    - V3: [8197, 1080, 1920, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:19:06.705108Z",
     "iopub.status.busy": "2020-10-27T15:19:06.705108Z",
     "iopub.status.idle": "2020-10-27T15:19:06.722106Z",
     "shell.execute_reply": "2020-10-27T15:19:06.722106Z",
     "shell.execute_reply.started": "2020-10-27T15:19:06.705108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252.mp4 V1: [2756, 360, 640, 3] and V3: [2755, 360, 640, 3]\n",
      "video30.mp4 V1: [8217, 1080, 1920, 3] and V3: [8197, 1080, 1920, 3]\n"
     ]
    }
   ],
   "source": [
    "for video in AW2_videos_FN:\n",
    "    if (AW2_seqlength.get(video) == AW2_seqlength_V3.get(video)) == False:\n",
    "        print(\n",
    "            video,\n",
    "            f\"V1: {AW2_seqlength_V2.get(video)} and V3: {AW2_seqlength_V3.get(video)}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:49:30.050486Z",
     "iopub.status.busy": "2020-10-27T15:49:30.050486Z",
     "iopub.status.idle": "2020-10-27T15:49:30.059486Z",
     "shell.execute_reply": "2020-10-27T15:49:30.059486Z",
     "shell.execute_reply.started": "2020-10-27T15:49:30.050486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save json file with all video's names and shapes = (n_frames, width, height, colour channels)\n",
    "with open(\"AW2_video_shapes.json\", \"w\") as fp:\n",
    "    json.dump(AW2_seqlength, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T15:49:32.501293Z",
     "iopub.status.busy": "2020-10-27T15:49:32.501293Z",
     "iopub.status.idle": "2020-10-27T15:49:32.512292Z",
     "shell.execute_reply": "2020-10-27T15:49:32.512292Z",
     "shell.execute_reply.started": "2020-10-27T15:49:32.501293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Aff-Wild2 video_shapes.json\n",
    "with open(\"AW2_video_shapes.json\", \"r\") as fp:\n",
    "    AW2_video_shapes = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes per video in training and validation set ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:15:34.636688Z",
     "iopub.status.busy": "2020-10-27T16:15:34.635686Z",
     "iopub.status.idle": "2020-10-27T16:15:34.821685Z",
     "shell.execute_reply": "2020-10-27T16:15:34.821685Z",
     "shell.execute_reply.started": "2020-10-27T16:15:34.636688Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all txt files and create dictionary where each key is the filename and value is all the values (annotations) in the text file\n",
    "AW2_train_classes = {}\n",
    "for ann_file in AW2_train_FN:\n",
    "    with open(join(AW2_dir_train_labels, ann_file), \"r\") as fp:\n",
    "        AW2_train_classes[ann_file] = np.array(fp.read().splitlines()[1:], dtype=int)\n",
    "\n",
    "AW2_val_classes = {}\n",
    "for ann_file in AW2_val_FN:\n",
    "    with open(join(AW2_dir_val_labels, ann_file), \"r\") as fp:\n",
    "        AW2_val_classes[ann_file] = np.array(fp.read().splitlines()[1:], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that each annotated file has about 0 to 2 more annotations than the amount of frames in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:35:13.950800Z",
     "iopub.status.busy": "2020-10-27T16:35:13.950800Z",
     "iopub.status.idle": "2020-10-27T16:35:13.995802Z",
     "shell.execute_reply": "2020-10-27T16:35:13.994801Z",
     "shell.execute_reply.started": "2020-10-27T16:35:13.950800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['10-60-1280x720.txt'] has 1 more annotation than frames\n",
      "['10-60-1280x720_right.txt'] has 1 more annotation than frames\n",
      "['100-29-1080x1920.txt'] has 1 more annotation than frames\n",
      "['101-30-1080x1920.txt'] has 1 more annotation than frames\n",
      "['102-30-640x360.txt'] has 1 more annotation than frames\n",
      "['102.txt'] has 1 more annotation than frames\n",
      "['103-30-384x480.txt'] has 1 more annotation than frames\n",
      "['103.txt'] has 1 more annotation than frames\n",
      "['104-17-720x480.txt'] has 1 more annotation than frames\n",
      "['105-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['105.txt'] has 1 more annotation than frames\n",
      "['106-30-720x1280.txt'] has 1 more annotation than frames\n",
      "['106.txt'] has 2 more annotation than frames\n",
      "['107-30-640x480.txt'] has 0 more annotation than frames\n",
      "['107.txt'] has 1 more annotation than frames\n",
      "['108-15-640x480.txt'] has 1 more annotation than frames\n",
      "['108.txt'] has 2 more annotation than frames\n",
      "['109-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['11-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['110-30-270x480.txt'] has 1 more annotation than frames\n",
      "['110.txt'] has 1 more annotation than frames\n",
      "['111-25-1920x1080.txt'] has 1 more annotation than frames\n",
      "['111.txt'] has 1 more annotation than frames\n",
      "['112-30-640x360.txt'] has 0 more annotation than frames\n",
      "['112.txt'] has 2 more annotation than frames\n",
      "['113-60-1280x720.txt'] has 0 more annotation than frames\n",
      "['113.txt'] has 1 more annotation than frames\n",
      "['114-30-1280x720.txt'] has 0 more annotation than frames\n",
      "['114.txt'] has 1 more annotation than frames\n",
      "['115-30-1280x720.txt'] has 0 more annotation than frames\n",
      "['116-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['116.txt'] has 1 more annotation than frames\n",
      "['117-25-1920x1080.txt'] has 1 more annotation than frames\n",
      "['12-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['122-60-1920x1080-1.txt'] has 1 more annotation than frames\n",
      "['13-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['132-30-426x240.txt'] has 0 more annotation than frames\n",
      "['133-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['135-24-1920x1080_right.txt'] has 1 more annotation than frames\n",
      "['138-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['139-14-720x480.txt'] has 1 more annotation than frames\n",
      "['15-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['17-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['18-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['19-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['198.txt'] has 1 more annotation than frames\n",
      "['2-30-640x360.txt'] has 1 more annotation than frames\n",
      "['20-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['207.txt'] has 2 more annotation than frames\n",
      "['21-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['22-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['225.txt'] has 0 more annotation than frames\n",
      "['23-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['24-30-1920x1080-1.txt'] has 1 more annotation than frames\n",
      "['25-25-600x480.txt'] has 1 more annotation than frames\n",
      "['26-60-1280x720.txt'] has 1 more annotation than frames\n",
      "['27-60-1280x720.txt'] has 1 more annotation than frames\n",
      "['28-30-1280x720-1.txt'] has 1 more annotation than frames\n",
      "['28-30-1280x720-3.txt'] has 1 more annotation than frames\n",
      "['28-30-1280x720-4.txt'] has 1 more annotation than frames\n",
      "['29-24-1280x720.txt'] has 1 more annotation than frames\n",
      "['3-25-1920x1080.txt'] has 1 more annotation than frames\n",
      "['31-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['32-60-1920x1080.txt'] has 1 more annotation than frames\n",
      "['325.txt'] has 0 more annotation than frames\n",
      "['326.txt'] has 1 more annotation than frames\n",
      "['327.txt'] has -1 more annotation than frames\n",
      "['328.txt'] has 0 more annotation than frames\n",
      "['329.txt'] has 1 more annotation than frames\n",
      "['33-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['330.txt'] has 1 more annotation than frames\n",
      "['331.txt'] has 1 more annotation than frames\n",
      "['332.txt'] has 0 more annotation than frames\n",
      "['334.txt'] has 0 more annotation than frames\n",
      "['335.txt'] has 0 more annotation than frames\n",
      "['336.txt'] has 0 more annotation than frames\n",
      "['337.txt'] has 0 more annotation than frames\n",
      "['339.txt'] has -1 more annotation than frames\n",
      "['34-25-1920x1080.txt'] has 1 more annotation than frames\n",
      "['341.txt'] has 2 more annotation than frames\n",
      "['344.txt'] has 0 more annotation than frames\n",
      "['345.txt'] has 1 more annotation than frames\n",
      "['346.txt'] has 1 more annotation than frames\n",
      "['347.txt'] has 0 more annotation than frames\n",
      "['348.txt'] has -1 more annotation than frames\n",
      "['349.txt'] has 0 more annotation than frames\n",
      "['35-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['350.txt'] has 0 more annotation than frames\n",
      "['353.txt'] has 0 more annotation than frames\n",
      "['354.txt'] has 1 more annotation than frames\n",
      "['355.txt'] has 1 more annotation than frames\n",
      "['357.txt'] has 0 more annotation than frames\n",
      "['358.txt'] has 0 more annotation than frames\n",
      "['359.txt'] has 0 more annotation than frames\n",
      "['36-24-1280x720.txt'] has 1 more annotation than frames\n",
      "['360.txt'] has 0 more annotation than frames\n",
      "['361.txt'] has 0 more annotation than frames\n",
      "['362.txt'] has 0 more annotation than frames\n",
      "['363.txt'] has 0 more annotation than frames\n",
      "['364.txt'] has 0 more annotation than frames\n",
      "['365.txt'] has 0 more annotation than frames\n",
      "['367.txt'] has 0 more annotation than frames\n",
      "['368.txt'] has 0 more annotation than frames\n",
      "['369.txt'] has 0 more annotation than frames\n",
      "['37-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['370.txt'] has 0 more annotation than frames\n",
      "['371.txt'] has 0 more annotation than frames\n",
      "['372.txt'] has 0 more annotation than frames\n",
      "['373.txt'] has 0 more annotation than frames\n",
      "['374.txt'] has 0 more annotation than frames\n",
      "['375.txt'] has 0 more annotation than frames\n",
      "['376.txt'] has 1 more annotation than frames\n",
      "['377.txt'] has -1 more annotation than frames\n",
      "['378.txt'] has 0 more annotation than frames\n",
      "['38-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['380.txt'] has 0 more annotation than frames\n",
      "['381.txt'] has 0 more annotation than frames\n",
      "['382.txt'] has 0 more annotation than frames\n",
      "['383.txt'] has 0 more annotation than frames\n",
      "['384.txt'] has 0 more annotation than frames\n",
      "['385.txt'] has 0 more annotation than frames\n",
      "['386.txt'] has 1 more annotation than frames\n",
      "['387.txt'] has 0 more annotation than frames\n",
      "['388.txt'] has 1 more annotation than frames\n",
      "['389.txt'] has 1 more annotation than frames\n",
      "['39-25-424x240.txt'] has 1 more annotation than frames\n",
      "['391.txt'] has 0 more annotation than frames\n",
      "['392.txt'] has 0 more annotation than frames\n",
      "['393.txt'] has -1 more annotation than frames\n",
      "['394.txt'] has 0 more annotation than frames\n",
      "['395.txt'] has 0 more annotation than frames\n",
      "['398.txt'] has 0 more annotation than frames\n",
      "['399.txt'] has 1 more annotation than frames\n",
      "['4-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['400.txt'] has 0 more annotation than frames\n",
      "['402.txt'] has 0 more annotation than frames\n",
      "['403.txt'] has 0 more annotation than frames\n",
      "['406.txt'] has 0 more annotation than frames\n",
      "['407.txt'] has 0 more annotation than frames\n",
      "['408.txt'] has 0 more annotation than frames\n",
      "['409.txt'] has 0 more annotation than frames\n",
      "['41-24-1280x720.txt'] has 1 more annotation than frames\n",
      "['412.txt'] has 0 more annotation than frames\n",
      "['415.txt'] has 0 more annotation than frames\n",
      "['416.txt'] has 1 more annotation than frames\n",
      "['418.txt'] has 0 more annotation than frames\n",
      "['419.txt'] has 0 more annotation than frames\n",
      "['42-30-480x480.txt'] has 1 more annotation than frames\n",
      "['420.txt'] has 0 more annotation than frames\n",
      "['421.txt'] has 0 more annotation than frames\n",
      "['423.txt'] has 0 more annotation than frames\n",
      "['424.txt'] has 1 more annotation than frames\n",
      "['425.txt'] has 0 more annotation than frames\n",
      "['426.txt'] has 0 more annotation than frames\n",
      "['427.txt'] has 0 more annotation than frames\n",
      "['428.txt'] has 0 more annotation than frames\n",
      "['429.txt'] has 1 more annotation than frames\n",
      "['430.txt'] has 0 more annotation than frames\n",
      "['433.txt'] has 1 more annotation than frames\n",
      "['434.txt'] has 1 more annotation than frames\n",
      "['435.txt'] has 0 more annotation than frames\n",
      "['439.txt'] has 0 more annotation than frames\n",
      "['44-25-426x240.txt'] has 1 more annotation than frames\n",
      "['440.txt'] has 0 more annotation than frames\n",
      "['441.txt'] has 0 more annotation than frames\n",
      "['446.txt'] has 0 more annotation than frames\n",
      "['447.txt'] has -1 more annotation than frames\n",
      "['448.txt'] has 0 more annotation than frames\n",
      "['449.txt'] has 1 more annotation than frames\n",
      "['450.txt'] has 0 more annotation than frames\n",
      "['46-30-484x360_left.txt'] has 1 more annotation than frames\n",
      "['46-30-484x360_right.txt'] has 1 more annotation than frames\n",
      "['47-30-654x480.txt'] has 1 more annotation than frames\n",
      "['48-30-720x1280.txt'] has 1 more annotation than frames\n",
      "['5-60-1920x1080-1.txt'] has 1 more annotation than frames\n",
      "['5-60-1920x1080-2.txt'] has 1 more annotation than frames\n",
      "['5-60-1920x1080-3.txt'] has 1 more annotation than frames\n",
      "['5-60-1920x1080-4.txt'] has 1 more annotation than frames\n",
      "['50-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['51-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['53-30-360x480.txt'] has 1 more annotation than frames\n",
      "['54-30-1080x1920.txt'] has 1 more annotation than frames\n",
      "['55-25-1280x720.txt'] has 1 more annotation than frames\n",
      "['56-30-1080x1920.txt'] has 1 more annotation than frames\n",
      "['57-25-426x240.txt'] has 1 more annotation than frames\n",
      "['58-30-640x480.txt'] has 1 more annotation than frames\n",
      "['59-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['6-30-1920x1080_left.txt'] has 1 more annotation than frames\n",
      "['60-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['61-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['62-30-654x480.txt'] has 1 more annotation than frames\n",
      "['63-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['64-24-640x360.txt'] has 1 more annotation than frames\n",
      "['65-30-400x228.txt'] has 1 more annotation than frames\n",
      "['66-25-1080x1920.txt'] has 1 more annotation than frames\n",
      "['67-24-640x360.txt'] has 1 more annotation than frames\n",
      "['68-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['69-25-854x480.txt'] has 1 more annotation than frames\n",
      "['7-60-1920x1080.txt'] has 1 more annotation than frames\n",
      "['70-30-720x1280.txt'] has 1 more annotation than frames\n",
      "['71-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['72-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['74-25-1920x1080.txt'] has 1 more annotation than frames\n",
      "['75-30-960x720.txt'] has 1 more annotation than frames\n",
      "['76-30-640x280.txt'] has 1 more annotation than frames\n",
      "['77-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['78-30-960x720.txt'] has 1 more annotation than frames\n",
      "['8-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['80-30-320x240.txt'] has 1 more annotation than frames\n",
      "['81-30-576x360.txt'] has 0 more annotation than frames\n",
      "['83-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['84-30-1920x1080.txt'] has 0 more annotation than frames\n",
      "['85-24-1280x720.txt'] has 1 more annotation than frames\n",
      "['86-24-1920x1080.txt'] has 0 more annotation than frames\n",
      "['87-25-1920x1080.txt'] has 1 more annotation than frames\n",
      "['88-30-360x480.txt'] has 1 more annotation than frames\n",
      "['89-30-1080x1920.txt'] has 1 more annotation than frames\n",
      "['9-15-1920x1080.txt'] has 1 more annotation than frames\n",
      "['90-30-1080x1920.txt'] has 1 more annotation than frames\n",
      "['91-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['93-24-640x360.txt'] has 1 more annotation than frames\n",
      "['94-30-1920x1080.txt'] has 1 more annotation than frames\n",
      "['95-24-1920x1080.txt'] has 1 more annotation than frames\n",
      "['96-30-1280x720.txt'] has 1 more annotation than frames\n",
      "['97-29-1920x1080.txt'] has 1 more annotation than frames\n",
      "['98-30-360x360.txt'] has 1 more annotation than frames\n",
      "['99-30-720x720.txt'] has 1 more annotation than frames\n",
      "['video1.txt'] has 0 more annotation than frames\n",
      "['video2.txt'] has 1 more annotation than frames\n",
      "['video24.txt'] has 1 more annotation than frames\n",
      "['video2_left.txt'] has 1 more annotation than frames\n",
      "['video3.txt'] has 1 more annotation than frames\n",
      "['video4.txt'] has 1 more annotation than frames\n",
      "['video45_3.txt'] has 1 more annotation than frames\n",
      "['video45_5.txt'] has 1 more annotation than frames\n",
      "['video45_6.txt'] has 1 more annotation than frames\n",
      "['video45_7.txt'] has 1 more annotation than frames\n",
      "['video47.txt'] has 1 more annotation than frames\n",
      "['video48.txt'] has 1 more annotation than frames\n",
      "['video49_left.txt'] has 1 more annotation than frames\n",
      "['video58.txt'] has 0 more annotation than frames\n",
      "['video6.txt'] has 1 more annotation than frames\n",
      "['video61.txt'] has 0 more annotation than frames\n",
      "['video63.txt'] has 0 more annotation than frames\n",
      "['video66.txt'] has 0 more annotation than frames\n",
      "['video67.txt'] has 0 more annotation than frames\n",
      "['video7.txt'] has 1 more annotation than frames\n",
      "['video72.txt'] has 0 more annotation than frames\n",
      "['video79.txt'] has 0 more annotation than frames\n",
      "['video8.txt'] has 1 more annotation than frames\n",
      "['video93.txt'] has 0 more annotation than frames\n",
      "['video94.txt'] has 0 more annotation than frames\n"
     ]
    }
   ],
   "source": [
    "# Checking if the lentgh of each text annotated file is the same as the amount of frames in a video.\n",
    "for ann_file in AW2_train_FN:\n",
    "    name, ext = splitext(ann_file)\n",
    "    if \"_left\" in name:\n",
    "        name = name.replace(\"_left\", \"\")\n",
    "    elif \"_right\" in name:\n",
    "        name = name.replace(\"_right\", \"\")\n",
    "    x = AW2_seqlength_without_extension.get(name)[0]\n",
    "    y = len(AW2_train_classes.get(ann_file))\n",
    "    print([ann_file], f\"has {y-x} more annotation than frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:35:08.874759Z",
     "iopub.status.busy": "2020-10-27T16:35:08.874759Z",
     "iopub.status.idle": "2020-10-27T16:35:08.895760Z",
     "shell.execute_reply": "2020-10-27T16:35:08.895760Z",
     "shell.execute_reply.started": "2020-10-27T16:35:08.874759Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['117.txt']  has 1 more annotation than frames\n",
      "['118-30-640x480.txt']  has 0 more annotation than frames\n",
      "['118.txt']  has 1 more annotation than frames\n",
      "['119-30-848x480.txt']  has 1 more annotation than frames\n",
      "['119.txt']  has 2 more annotation than frames\n",
      "['120-30-1280x720.txt']  has 0 more annotation than frames\n",
      "['120.txt']  has 1 more annotation than frames\n",
      "['121-24-1920x1080.txt']  has 1 more annotation than frames\n",
      "['121.txt']  has 1 more annotation than frames\n",
      "['122-60-1920x1080-2.txt']  has 1 more annotation than frames\n",
      "['122-60-1920x1080-3.txt']  has 1 more annotation than frames\n",
      "['122-60-1920x1080-4.txt']  has 1 more annotation than frames\n",
      "['122.txt']  has 1 more annotation than frames\n",
      "['123-25-1920x1080.txt']  has 1 more annotation than frames\n",
      "['123.txt']  has 1 more annotation than frames\n",
      "['124-30-720x1280.txt']  has 1 more annotation than frames\n",
      "['125-25-1280x720.txt']  has 1 more annotation than frames\n",
      "['125.txt']  has 1 more annotation than frames\n",
      "['126.txt']  has 1 more annotation than frames\n",
      "['127-30-1280x720.txt']  has 0 more annotation than frames\n",
      "['127.txt']  has 1 more annotation than frames\n",
      "['128-24-1920x1080.txt']  has 1 more annotation than frames\n",
      "['128.txt']  has 1 more annotation than frames\n",
      "['129-24-1280x720.txt']  has 1 more annotation than frames\n",
      "['129.txt']  has 2 more annotation than frames\n",
      "['130.txt']  has 1 more annotation than frames\n",
      "['131-30-1920x1080.txt']  has 1 more annotation than frames\n",
      "['131.txt']  has 2 more annotation than frames\n",
      "['132.txt']  has 1 more annotation than frames\n",
      "['133.txt']  has 1 more annotation than frames\n",
      "['134.txt']  has 1 more annotation than frames\n",
      "['135-24-1920x1080_left.txt']  has 1 more annotation than frames\n",
      "['135.txt']  has 2 more annotation than frames\n",
      "['136.txt']  has 1 more annotation than frames\n",
      "['137-30-1920x1080.txt']  has 1 more annotation than frames\n",
      "['137.txt']  has 1 more annotation than frames\n",
      "['138.txt']  has 1 more annotation than frames\n",
      "['139.txt']  has 1 more annotation than frames\n",
      "['140-30-632x360.txt']  has 1 more annotation than frames\n",
      "['140.txt']  has 1 more annotation than frames\n",
      "['141.txt']  has 1 more annotation than frames\n",
      "['143.txt']  has 1 more annotation than frames\n",
      "['144.txt']  has 1 more annotation than frames\n",
      "['146.txt']  has 2 more annotation than frames\n",
      "['147.txt']  has 1 more annotation than frames\n",
      "['148.txt']  has 1 more annotation than frames\n",
      "['149.txt']  has 1 more annotation than frames\n",
      "['150.txt']  has 1 more annotation than frames\n",
      "['151.txt']  has 1 more annotation than frames\n",
      "['153.txt']  has 1 more annotation than frames\n",
      "['154.txt']  has 1 more annotation than frames\n",
      "['155.txt']  has 1 more annotation than frames\n",
      "['156.txt']  has 1 more annotation than frames\n",
      "['157.txt']  has 1 more annotation than frames\n",
      "['158.txt']  has 1 more annotation than frames\n",
      "['159.txt']  has 1 more annotation than frames\n",
      "['160.txt']  has 1 more annotation than frames\n",
      "['161.txt']  has 1 more annotation than frames\n",
      "['162.txt']  has 1 more annotation than frames\n",
      "['163.txt']  has 1 more annotation than frames\n",
      "['164.txt']  has 1 more annotation than frames\n",
      "['165.txt']  has 1 more annotation than frames\n",
      "['24-30-1920x1080-2.txt']  has 1 more annotation than frames\n",
      "['28-30-1280x720-2.txt']  has 1 more annotation than frames\n",
      "['282.txt']  has 0 more annotation than frames\n",
      "['45-24-1280x720.txt']  has 1 more annotation than frames\n",
      "['6-30-1920x1080_right.txt']  has 1 more annotation than frames\n",
      "['82-25-854x480.txt']  has 1 more annotation than frames\n",
      "['video34.txt']  has 1 more annotation than frames\n",
      "['video73.txt']  has 0 more annotation than frames\n"
     ]
    }
   ],
   "source": [
    "# Checking if the lentgh of each text annotated file is the same as the amount of frames in a video.\n",
    "for ann_file in AW2_val_FN:\n",
    "    name, ext = splitext(ann_file)\n",
    "    if \"_left\" in name:\n",
    "        name = name.replace(\"_left\", \"\")\n",
    "    elif \"_right\" in name:\n",
    "        name = name.replace(\"_right\", \"\")\n",
    "    x = AW2_seqlength_without_extension.get(name)[0]\n",
    "    y = len(AW2_val_classes.get(ann_file))\n",
    "    print([ann_file], f\" has {y-x} more annotation than frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:33:46.854431Z",
     "iopub.status.busy": "2020-10-27T16:33:46.854431Z",
     "iopub.status.idle": "2020-10-27T16:33:46.862431Z",
     "shell.execute_reply": "2020-10-27T16:33:46.861430Z",
     "shell.execute_reply.started": "2020-10-27T16:33:46.854431Z"
    }
   },
   "source": [
    "### Distribution of each class per video and set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:56:32.218760Z",
     "iopub.status.busy": "2020-10-27T16:56:32.217760Z",
     "iopub.status.idle": "2020-10-27T16:56:32.263758Z",
     "shell.execute_reply": "2020-10-27T16:56:32.263758Z",
     "shell.execute_reply.started": "2020-10-27T16:56:32.218760Z"
    }
   },
   "outputs": [],
   "source": [
    "names_class =  ['neutral', 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "\n",
    "AW2_train_classdist = {}\n",
    "for ann_file in AW2_train_FN:\n",
    "    values = AW2_train_classes.get(ann_file)\n",
    "    AW2_train_classdist[ann_file] = {name:np.sum(values == i) for name, i in zip(names_class,range(0,7))}\n",
    "    \n",
    "AW2_val_classdist = {}\n",
    "for ann_file in AW2_val_FN:\n",
    "    values = AW2_val_classes.get(ann_file)\n",
    "    AW2_val_classdist[ann_file] = {name:np.sum(values == i) for name, i in zip(names_class,range(0,7))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T16:33:46.854431Z",
     "iopub.status.busy": "2020-10-27T16:33:46.854431Z",
     "iopub.status.idle": "2020-10-27T16:33:46.862431Z",
     "shell.execute_reply": "2020-10-27T16:33:46.861430Z",
     "shell.execute_reply.started": "2020-10-27T16:33:46.854431Z"
    }
   },
   "source": [
    "### Distribution of each class per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T17:37:39.405079Z",
     "iopub.status.busy": "2020-10-27T17:37:39.405079Z",
     "iopub.status.idle": "2020-10-27T17:37:39.423074Z",
     "shell.execute_reply": "2020-10-27T17:37:39.423074Z",
     "shell.execute_reply.started": "2020-10-27T17:37:39.405079Z"
    }
   },
   "outputs": [],
   "source": [
    "AW2_train_highlevel_dist = {i:0 for i in names_class}\n",
    "\n",
    "for ann_file in AW2_train_FN:\n",
    "    values = AW2_train_classdist.get(ann_file)\n",
    "    for name in AW2_train_highlevel_dist.keys():\n",
    "        AW2_train_highlevel_dist[name]+= values.get(name)\n",
    "\n",
    "        \n",
    "AW2_val_highlevel_dist = {i:0 for i in names_class}\n",
    "\n",
    "for ann_file in AW2_val_FN:\n",
    "    values = AW2_val_classdist.get(ann_file)\n",
    "    for name in AW2_val_highlevel_dist.keys():\n",
    "        AW2_val_highlevel_dist[name]+= values.get(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T17:50:13.386934Z",
     "iopub.status.busy": "2020-10-27T17:50:13.386934Z",
     "iopub.status.idle": "2020-10-27T17:50:13.397934Z",
     "shell.execute_reply": "2020-10-27T17:50:13.397934Z",
     "shell.execute_reply.started": "2020-10-27T17:50:13.386934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 589215,\n",
       " 'anger': 24080,\n",
       " 'disgust': 12704,\n",
       " 'fear': 11155,\n",
       " 'happiness': 152010,\n",
       " 'sadness': 101295,\n",
       " 'surprise': 39035}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of classes for training set\n",
    "AW2_train_highlevel_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T17:51:48.027105Z",
     "iopub.status.busy": "2020-10-27T17:51:48.027105Z",
     "iopub.status.idle": "2020-10-27T17:51:48.033105Z",
     "shell.execute_reply": "2020-10-27T17:51:48.033105Z",
     "shell.execute_reply.started": "2020-10-27T17:51:48.027105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 63.39,\n",
       " 'anger': 2.59,\n",
       " 'disgust': 1.37,\n",
       " 'fear': 1.2,\n",
       " 'happiness': 16.35,\n",
       " 'sadness': 10.9,\n",
       " 'surprise': 4.2}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of class for training set in percentages\n",
    "{name:round((value/sum(AW2_train_highlevel_dist.values()))*100,2) for name, value in zip(names_class, AW2_train_highlevel_dist.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T17:51:25.806901Z",
     "iopub.status.busy": "2020-10-27T17:51:25.806901Z",
     "iopub.status.idle": "2020-10-27T17:51:25.811898Z",
     "shell.execute_reply": "2020-10-27T17:51:25.811898Z",
     "shell.execute_reply.started": "2020-10-27T17:51:25.806901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 183652,\n",
       " 'anger': 8004,\n",
       " 'disgust': 5825,\n",
       " 'fear': 9754,\n",
       " 'happiness': 53713,\n",
       " 'sadness': 39493,\n",
       " 'surprise': 23113}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of classes for validation set\n",
    "AW2_val_highlevel_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T17:52:36.478832Z",
     "iopub.status.busy": "2020-10-27T17:52:36.478832Z",
     "iopub.status.idle": "2020-10-27T17:52:36.484833Z",
     "shell.execute_reply": "2020-10-27T17:52:36.484833Z",
     "shell.execute_reply.started": "2020-10-27T17:52:36.478832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 56.76,\n",
       " 'anger': 2.47,\n",
       " 'disgust': 1.8,\n",
       " 'fear': 3.01,\n",
       " 'happiness': 16.6,\n",
       " 'sadness': 12.21,\n",
       " 'surprise': 7.14}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of class for training set in percentages\n",
    "{name:round((value/sum(AW2_val_highlevel_dist.values()))*100,2) for name, value in zip(names_class, AW2_val_highlevel_dist.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
