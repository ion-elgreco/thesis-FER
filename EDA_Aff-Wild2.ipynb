{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:09.746818Z",
     "iopub.status.busy": "2020-10-27T11:49:09.746818Z",
     "iopub.status.idle": "2020-10-27T11:49:10.179852Z",
     "shell.execute_reply": "2020-10-27T11:49:10.179852Z",
     "shell.execute_reply.started": "2020-10-27T11:49:09.746818Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from os.path import join\n",
    "\n",
    "import skvideo\n",
    "skvideo.setFFmpegPath(r'C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\Lib\\site-packages\\ffmpeg-4.3.1-2020-10-01-full_build\\bin')\n",
    "import skvideo.io\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of different datasets\n",
    "The Aff-Wild2 dataset is used for training, validation and testing. While the AFEW 7.0 dataset is only used for testing. \n",
    "\n",
    "#### Aff-Wild2\n",
    "In this dataset all videos are in one folder. Each video has a corresponding .txt file where each frame is annotated with the correspending facial expression class at that frame. In each video multiple emotions are displayed, thats why the annotation is per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:11.004769Z",
     "iopub.status.busy": "2020-10-27T11:49:11.004769Z",
     "iopub.status.idle": "2020-10-27T11:49:11.022769Z",
     "shell.execute_reply": "2020-10-27T11:49:11.022769Z",
     "shell.execute_reply.started": "2020-10-27T11:49:11.004769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aff-Wild2 = AW2\n",
    "# filenames = FN\n",
    "\n",
    "### Aff-wild2 ###\n",
    "# Directories for labels/annotations for each set\n",
    "AW2_dir_train_labels = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Videos\\annotations\\EXPR_Set\\Training_Set\"\n",
    "AW2_dir_val_labels = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Videos\\annotations\\EXPR_Set\\Validation_Set\"\n",
    "\n",
    "# Directories for videos\n",
    "AW2_dir_allvideos = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Videos\\all_videos\"\n",
    "\n",
    "# Save the filenames in a list for each set, and split the filename from the extension\n",
    "AW2_train_FN = listdir(AW2_dir_train_labels)\n",
    "AW2_train_FN_split = [splitext(file) for file in AW2_train_FN]\n",
    "\n",
    "AW2_val_FN = listdir(AW2_dir_val_labels)\n",
    "AW2_val_FN_split = [splitext(file) for file in AW2_val_FN]\n",
    "\n",
    "AW2_videos_FN = listdir(AW2_dir_allvideos)\n",
    "AW2_videos_FN_split = [splitext(file) for file in AW2_videos_FN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aff-wild2 Dataset Size ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:13.401133Z",
     "iopub.status.busy": "2020-10-27T11:49:13.401133Z",
     "iopub.status.idle": "2020-10-27T11:49:13.418134Z",
     "shell.execute_reply": "2020-10-27T11:49:13.417132Z",
     "shell.execute_reply.started": "2020-10-27T11:49:13.401133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training-set contains 253 videos\n",
      "The validation-set contains 70 videos\n",
      "The test-set contains 225 videos\n",
      "The whole dataset contains 548 videos\n"
     ]
    }
   ],
   "source": [
    "# Size of each set\n",
    "print(f\"The training-set contains {len(AW2_train_FN)} videos\")\n",
    "print(f\"The validation-set contains {len(AW2_val_FN)} videos\")\n",
    "print(f\"The test-set contains {len(AW2_videos_FN) - (len(AW2_train_FN) + len(AW2_val_FN))} videos\")\n",
    "print(f\"The whole dataset contains {len(AW2_videos_FN)} videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:13.689164Z",
     "iopub.status.busy": "2020-10-27T11:49:13.689164Z",
     "iopub.status.idle": "2020-10-27T11:49:13.716163Z",
     "shell.execute_reply": "2020-10-27T11:49:13.716163Z",
     "shell.execute_reply.started": "2020-10-27T11:49:13.689164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "# Checking if the labeled filenames corresponds to the videos\n",
    "train_size = 0\n",
    "for i in AW2_train_FN_split:\n",
    "    for j in AW2_videos_FN_split:\n",
    "        if i[0] == j[0]:\n",
    "            train_size+=1\n",
    "    \n",
    "## The results show that only 246 labels are matched to videos, while there were 253 labeled videos\n",
    "## Some videos contain two persons, so the labels are for one person on the left or right\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:13.949360Z",
     "iopub.status.busy": "2020-10-27T11:49:13.949360Z",
     "iopub.status.idle": "2020-10-27T11:49:13.992359Z",
     "shell.execute_reply": "2020-10-27T11:49:13.992359Z",
     "shell.execute_reply.started": "2020-10-27T11:49:13.949360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset is indeed = 253 videos\n",
      "Validation dataset is indeed = 70 videos\n"
     ]
    }
   ],
   "source": [
    "# Checking if the labeled filenames corresponds to the videos (and disregarding if its on left or right)\n",
    "train_size = 0\n",
    "for i in AW2_train_FN_split:\n",
    "    for j in AW2_videos_FN_split:\n",
    "        if '_left' in i[0]:\n",
    "            a = i[0].replace('_left', '')\n",
    "        elif '_right' in i[0]:\n",
    "            a = i[0].replace('_right', '')\n",
    "        else:\n",
    "            a = i[0]\n",
    "        if a == j[0]:\n",
    "            train_size+=1\n",
    "# Labels is equal to videos now\n",
    "print(f'Training dataset is indeed = {train_size} videos')\n",
    "\n",
    "# Checking if the labeled filenames corresponds to the videos (and disregarding if its on left or right)\n",
    "val_size = 0\n",
    "for i in AW2_val_FN_split:\n",
    "    for j in AW2_videos_FN_split:\n",
    "        if '_left' in i[0]:\n",
    "            a = i[0].replace('_left', '')\n",
    "        elif '_right' in i[0]:\n",
    "            a = i[0].replace('_right', '')\n",
    "        else:\n",
    "            a = i[0]\n",
    "        if a == j[0]:\n",
    "            val_size+=1\n",
    "# Labels is equal to videos now\n",
    "print(f'Validation dataset is indeed = {val_size} videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence length of each video ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:17.265875Z",
     "iopub.status.busy": "2020-10-27T11:49:17.265875Z",
     "iopub.status.idle": "2020-10-27T11:49:42.008873Z",
     "shell.execute_reply": "2020-10-27T11:49:42.008873Z",
     "shell.execute_reply.started": "2020-10-27T11:49:17.265875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dictionary of sequence length of each video with ffprobe in skvideo\n",
    "AW2_seqlength = {}\n",
    "\n",
    "for video in AW2_videos_FN:\n",
    "    metadata = skvideo.io.ffprobe(join(AW2_dir_allvideos, video))\n",
    "    frames = int(metadata.get('video').get('@nb_frames'))\n",
    "    width = int(metadata.get('video').get('@width'))\n",
    "    height = int(metadata.get('video').get('@height'))\n",
    "    AW2_seqlength[video] = [frames, height, width, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:19:18.580168Z",
     "iopub.status.busy": "2020-10-27T12:19:18.580168Z",
     "iopub.status.idle": "2020-10-27T12:19:46.492166Z",
     "shell.execute_reply": "2020-10-27T12:19:46.492166Z",
     "shell.execute_reply.started": "2020-10-27T12:19:18.580168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dictionary of sequence length of each video with ffprobe in skvideo and opencv to capture the amount of frames\n",
    "AW2_seqlength_V2 = {}\n",
    "\n",
    "for video in AW2_videos_FN:\n",
    "    metadata = skvideo.io.ffprobe(join(AW2_dir_allvideos, video))\n",
    "    width = int(metadata.get('video').get('@width'))\n",
    "    height = int(metadata.get('video').get('@height'))\n",
    "    \n",
    "    cap = cv2.VideoCapture(join(AW2_dir_allvideos, video))\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    AW2_seqlength_V2[video] = [frames, height, width, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T13:27:42.781664Z",
     "iopub.status.busy": "2020-10-27T13:27:42.781664Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of sequence length of each video with ffprobe in skvideo and opencv to capture the amount of frames manually\n",
    "AW2_seqlength_V3 = {}\n",
    "\n",
    "counter = 0\n",
    "for video in AW2_videos_FN:\n",
    "    print(counter)\n",
    "    counter+=1\n",
    "    metadata = skvideo.io.ffprobe(join(AW2_dir_allvideos, video))\n",
    "    width = int(metadata.get('video').get('@width'))\n",
    "    height = int(metadata.get('video').get('@height'))\n",
    "    \n",
    "    frames = count_frames_manual(cv2.VideoCapture(join(AW2_dir_allvideos,video)))\n",
    "    AW2_seqlength_V3[video] = [frames, height, width, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:23:07.880258Z",
     "iopub.status.busy": "2020-10-27T12:23:07.880258Z",
     "iopub.status.idle": "2020-10-27T12:23:07.896257Z",
     "shell.execute_reply": "2020-10-27T12:23:07.896257Z",
     "shell.execute_reply.started": "2020-10-27T12:23:07.880258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the video length is the same with each method\n",
    "AW2_seqlength == AW2_seqlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save json file with all video's names and shapes = (n_frames, width, height, colour channels)\n",
    "with open('AW2_video_shapes.json', 'w') as fp:\n",
    "    json.dump(AW2_seqlength, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:24:37.647027Z",
     "iopub.status.busy": "2020-10-27T12:24:37.646026Z",
     "iopub.status.idle": "2020-10-27T12:24:37.665026Z",
     "shell.execute_reply": "2020-10-27T12:24:37.665026Z",
     "shell.execute_reply.started": "2020-10-27T12:24:37.647027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Aff-Wild2 video_shapes.json\n",
    "with open('AW2_video_shapes.json', 'r') as fp:\n",
    "    AW2_video_shapes = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
