{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T19:08:48.124041Z",
     "iopub.status.busy": "2020-11-11T19:08:48.124041Z",
     "iopub.status.idle": "2020-11-11T19:08:48.978039Z",
     "shell.execute_reply": "2020-11-11T19:08:48.977039Z",
     "shell.execute_reply.started": "2020-11-11T19:08:48.124041Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir, mkdir, rename\n",
    "from os.path import join, splitext\n",
    "from skimage import io, color, exposure\n",
    "\n",
    "# Import directories and filenames from own function\n",
    "from load_filenames import (\n",
    "    AW2_cropped_aligned_dir,  # 'D:\\\\Aff-Wild2 Dataset\\\\Aff-wild2\\\\Images\\\\cropped_aligned'\n",
    "    AW2_cropped_aligned_folders,  # Returns foldernames\n",
    "    AW2_train_FN_split,  # Returns videonames with\n",
    "    AW2_val_FN_split,\n",
    ")\n",
    "\n",
    "# Steps in this script\n",
    "# 1. Apply illumination normalization (histogram equalization)\n",
    "# 2. Store the frames (images) in a named folder same name as video. \n",
    "# 3. Move all files to the corresponding train, validation, test directory\n",
    "# 4. Put each corresponding frame in the correct class folder for training and validiation set.\n",
    "#    This is required for keras to read the image data from the directory in batches and assign the classes\n",
    "#    inferred from the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T19:14:19.267041Z",
     "iopub.status.busy": "2020-11-11T19:14:19.267041Z",
     "iopub.status.idle": "2020-11-11T19:14:19.274041Z",
     "shell.execute_reply": "2020-11-11T19:14:19.273040Z",
     "shell.execute_reply.started": "2020-11-11T19:14:19.267041Z"
    }
   },
   "outputs": [],
   "source": [
    "AW2_normalized_dir = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Images\\cropped_aligned_normalized\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T12:17:20.112920Z",
     "iopub.status.busy": "2020-11-03T12:17:20.112920Z",
     "iopub.status.idle": "2020-11-03T12:17:20.120917Z",
     "shell.execute_reply": "2020-11-03T12:17:20.120917Z",
     "shell.execute_reply.started": "2020-11-03T12:17:20.112920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-processing function\n",
    "\n",
    "# Each image has the shape (112, 112, 3)\n",
    "# To illumination normalize it with adaptive histogram equalization, the image is converted to grayscale and gets the shape (112, 112). \n",
    "# Afterwards it is converted back to RGB but remains the grayscale color. It's also converted back to values ranging from 0-255\n",
    "\n",
    "def pre_processing():\n",
    "    # Set timer\n",
    "    start = time.time()\n",
    "    \n",
    "    for folder in AW2_cropped_aligned_folders:\n",
    "        print(f'Processing this folder: {folder}')\n",
    "        \n",
    "        # Define the folder path to each video to grab the frames (images)\n",
    "        folder_dir = join(AW2_cropped_aligned_dir, folder)\n",
    "\n",
    "        # Create list of all the filenames of the corresponding folder\n",
    "        frames_FN = listdir(folder_dir)\n",
    "\n",
    "        \n",
    "        # Try to create a folder with the name of the video to save all the normalized frames\n",
    "        try:\n",
    "            mkdir(join(AW2_normalized_dir, folder))\n",
    "        except FileExistsError:\n",
    "            print(\"Directory already exists!\")\n",
    "\n",
    "        for frame_name in frames_FN:\n",
    "            # Added if statement, to skip this step if it sees this .ds_store file\n",
    "            if frame_name == \".DS_Store\":\n",
    "                continue\n",
    "            # Read img, convert it to grayscale else you cant adaptive histogram equalize it.\n",
    "            frame = io.imread(join(folder_dir, frame_name))\n",
    "            frame_g = color.rgb2gray(frame)\n",
    "            frame_g_hist = exposure.equalize_adapthist(frame_g)\n",
    "            # Convert it back to RGB, because VGG19 model requirs RGB images as input\n",
    "            frame_rgb_hist = color.gray2rgb(frame_g_hist)\n",
    "            \n",
    "            # Create path to save the normalized file\n",
    "            file = join(join(AW2_normalized_dir, folder), frame_name)\n",
    "            \n",
    "            # Save the file\n",
    "            io.imsave(file, (frame_rgb_hist * 255).astype(np.uint8))\n",
    "\n",
    "        print(\n",
    "            f\"Done! Time ran since start: {round(time.time()-start)//60 }:{round(time.time()-start)%60}\"\n",
    "        )\n",
    "    print('Finished pre-processing')\n",
    "pre_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T15:24:55.053254Z",
     "iopub.status.busy": "2020-11-03T15:24:55.053254Z",
     "iopub.status.idle": "2020-11-03T15:24:55.196251Z",
     "shell.execute_reply": "2020-11-03T15:24:55.196251Z",
     "shell.execute_reply.started": "2020-11-03T15:24:55.053254Z"
    }
   },
   "source": [
    "# Move images in their correct train, val and test set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T15:24:55.053254Z",
     "iopub.status.busy": "2020-11-03T15:24:55.053254Z",
     "iopub.status.idle": "2020-11-03T15:24:55.196251Z",
     "shell.execute_reply": "2020-11-03T15:24:55.196251Z",
     "shell.execute_reply.started": "2020-11-03T15:24:55.053254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set directories to move the images to\n",
    "train_dir = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Sets\\train\"\n",
    "val_dir = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Sets\\val\"\n",
    "test_dir = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Sets\\test\"\n",
    "\n",
    "# Load Aff-Wild2 AW2_train_classes.json\n",
    "with open(\"data/AW2_train_classes.json\", \"r\") as fp:\n",
    "    AW2_train_classes = json.load(fp)\n",
    "\n",
    "# Load Aff-Wild2 AW2_val_classes.json\n",
    "with open(\"data/AW2_val_classes.json\", \"r\") as fp:\n",
    "    AW2_val_classes = json.load(fp)\n",
    "    \n",
    "# Move training files\n",
    "for folder, ext in AW2_train_FN_split:\n",
    "    shutil.move(join(AW2_normalized_dir, folder), train_dir)\n",
    "\n",
    "for folder, ext in AW2_val_FN_split:\n",
    "    shutil.move(join(AW2_normalized_dir, folder), val_dir)\n",
    "\n",
    "for folder in listdir(AW2_normalized_dir):\n",
    "    shutil.move(join(AW2_normalized_dir, folder), test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T12:51:53.364822Z",
     "iopub.status.busy": "2020-11-03T12:51:53.364822Z",
     "iopub.status.idle": "2020-11-03T13:57:05.808123Z",
     "shell.execute_reply": "2020-11-03T13:57:05.805123Z",
     "shell.execute_reply.started": "2020-11-03T12:51:53.364822Z"
    }
   },
   "source": [
    "# Put each corresponding frame in the correct class folder for training and validiation set. \n",
    "This is necessary to create a dataset in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T12:51:53.364822Z",
     "iopub.status.busy": "2020-11-03T12:51:53.364822Z",
     "iopub.status.idle": "2020-11-03T13:57:05.808123Z",
     "shell.execute_reply": "2020-11-03T13:57:05.805123Z",
     "shell.execute_reply.started": "2020-11-03T12:51:53.364822Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract image from each videofolder and move it to the corresponding class folder\n",
    "train_perclass_dir = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Sets_per_class\\train\"\n",
    "label_folders = listdir(train_perclass_dir)\n",
    "\n",
    "for folder in listdir(train_dir):\n",
    "    ##e.g. returns folder: 51-30-1280x720\n",
    "\n",
    "    # Gets labels from the corresponding video from the AW2_train_classes dict\n",
    "    labels = AW2_train_classes.get(folder + \".txt\")\n",
    "\n",
    "    # Loop through each frame, and take the corresponding label for this frame from labels\n",
    "    for file in listdir(join(train_dir, folder)):\n",
    "        frame_n, ext = splitext(file)\n",
    "        frame_n = int(frame_n)\n",
    "        label = labels[(frame_n - 1)]\n",
    "\n",
    "        # If the label is between 0-6, create corresponding new directory\n",
    "        if label in [0, 1, 2, 3, 4, 5, 6]:\n",
    "            new_dir = join(train_perclass_dir, label_folders[label])\n",
    "        else:\n",
    "            continue\n",
    "        shutil.copy(join(train_dir, join(folder, file)), new_dir)\n",
    "        rename(join(new_dir, file), join(new_dir, folder + \"_\" + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image from each videofolder and move it to the corresponding class folder\n",
    "val_perclass_dir = r\"D:\\Aff-Wild2 Dataset\\Aff-wild2\\Sets_per_class\\val\"\n",
    "label_folders = listdir(val_perclass_dir)\n",
    "\n",
    "for folder in listdir(val_dir):\n",
    "    ##e.g. returns folder: 51-30-1280x720\n",
    "    # Gets labels from the corresponding video from the AW2_train_classes dict\n",
    "    labels = AW2_val_classes.get(folder + \".txt\")\n",
    "\n",
    "    # Loop through each frame, and take the corresponding label for this frame from labels\n",
    "    for file in listdir(join(val_dir, folder)):\n",
    "        frame_n, ext = splitext(file)\n",
    "        frame_n = int(frame_n)\n",
    "        label = labels[(frame_n - 1)]\n",
    "\n",
    "        # If the label is between 0-6, create corresponding new directory\n",
    "        if label in [0, 1, 2, 3, 4, 5, 6]:\n",
    "            new_dir = join(val_perclass_dir, label_folders[label])\n",
    "        else:\n",
    "            continue\n",
    "        shutil.copy(join(val_dir, join(folder, file)), new_dir)\n",
    "        rename(join(new_dir, file), join(new_dir, folder + \"_\" + file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
