{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T10:55:51.740213Z",
     "iopub.status.busy": "2020-11-25T10:55:51.739213Z",
     "iopub.status.idle": "2020-11-25T10:56:17.762214Z",
     "shell.execute_reply": "2020-11-25T10:56:17.761212Z",
     "shell.execute_reply.started": "2020-11-25T10:55:51.739213Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Import modules to run custom FW-RNN cell\n",
    "from tensorflow.python.keras.layers.recurrent import (\n",
    "    _generate_zero_filled_state_for_cell,\n",
    "    _generate_zero_filled_state,\n",
    "    ops,\n",
    "    tensor_shape,\n",
    "    activations,\n",
    "    initializers,\n",
    "    regularizers,\n",
    "    nest,\n",
    "    array_ops,\n",
    ")\n",
    "\n",
    "# Import variables and functions from my own scripts\n",
    "from functions import plot_history, arr_replacevalue\n",
    "from load_features import (\n",
    "    train_features_AW2,\n",
    "    val_features_AW2,\n",
    "    train_labels_AW2,\n",
    "    val_labels_AW2,\n",
    "    labels_reshaper,\n",
    "    features_reshaper,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Limit GPU memory usage\n",
    "for device in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T11:03:26.167198Z",
     "iopub.status.busy": "2020-11-25T11:03:26.167198Z",
     "iopub.status.idle": "2020-11-25T11:03:53.827146Z",
     "shell.execute_reply": "2020-11-25T11:03:53.813145Z",
     "shell.execute_reply.started": "2020-11-25T11:03:26.167198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape data to specified sequence length\n",
    "length = 60\n",
    "seq_train_features = features_reshaper(train_features_AW2, length) # divisible 13, 39, 197\n",
    "seq_val_features = features_reshaper(val_features_AW2, length)\n",
    "\n",
    "seq_train_labels = labels_reshaper(train_labels_AW2, length)\n",
    "seq_val_labels = labels_reshaper(val_labels_AW2, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T11:03:53.845147Z",
     "iopub.status.busy": "2020-11-25T11:03:53.844148Z",
     "iopub.status.idle": "2020-11-25T11:03:54.413146Z",
     "shell.execute_reply": "2020-11-25T11:03:54.412145Z",
     "shell.execute_reply.started": "2020-11-25T11:03:53.845147Z"
    }
   },
   "outputs": [],
   "source": [
    "def comp_sampleweights(labels):\n",
    "    # Convert one-hot encoded labels back to label integers\n",
    "    train_label_ints = np.argmax(labels, axis=2)\n",
    "\n",
    "    # Compute class weights with sklearn\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        \"balanced\", np.unique(train_label_ints), train_label_ints.flatten()\n",
    "    )\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample\n",
    "    return arr_replacevalue(train_label_ints, d_class_weights)\n",
    "    \n",
    "train_samples_weights = comp_sampleweights(seq_train_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T15:27:37.993463Z",
     "iopub.status.busy": "2020-11-11T15:27:37.993463Z",
     "iopub.status.idle": "2020-11-11T15:27:38.000462Z",
     "shell.execute_reply": "2020-11-11T15:27:38.000462Z",
     "shell.execute_reply.started": "2020-11-11T15:27:37.993463Z"
    }
   },
   "source": [
    "# Create FW-RNN Cell\n",
    "-  Build custom FW_RNN cell and wrap it in RNN layer (https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN), like this: RNN(FW_RNN)\n",
    "    -  \"The cell abstraction, together with the generic keras.layers.RNN class, make it very easy to implement custom RNN architectures for your research.\"\n",
    "\n",
    "Created by using this guide: https://www.tensorflow.org/guide/keras/custom_layers_and_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T11:03:54.421147Z",
     "iopub.status.busy": "2020-11-25T11:03:54.420147Z",
     "iopub.status.idle": "2020-11-25T11:03:54.999147Z",
     "shell.execute_reply": "2020-11-25T11:03:54.998146Z",
     "shell.execute_reply.started": "2020-11-25T11:03:54.421147Z"
    }
   },
   "outputs": [],
   "source": [
    "class FW_RNNCell(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        use_bias,\n",
    "        batch_size,\n",
    "        decay_rate,\n",
    "        learning_rate,\n",
    "        activation,\n",
    "        step,\n",
    "        LN = layers.LayerNormalization(),\n",
    "        **kwargs\n",
    "        \n",
    "    ):\n",
    "        super(FW_RNNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.step = step\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activations.get(activation)\n",
    "        self.l = decay_rate\n",
    "        self.e = learning_rate\n",
    "        self.LN = LN\n",
    "        \n",
    "\n",
    "        self.batch = batch_size\n",
    "        self.state_size = self.units\n",
    "\n",
    "        # Initializer & regularizer for the slow input-to-hidden weights matrix\n",
    "        self.C_initializer = initializers.get(\"glorot_uniform\")\n",
    "\n",
    "        # Initializer & regularizer for the slow hidden weights matrix\n",
    "        self.W_h_initializer = initializers.get(\"identity\")\n",
    "\n",
    "        # Initializer & regularizer for the fast weights matrix\n",
    "        self.A_initializer = initializers.get(\"zeros\")\n",
    "\n",
    "        # Initializer for the bias vector.\n",
    "        self.b_x_initializer = initializers.get(\"zeros\")\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Build is only called at the start, to initialize all the weights and biases\n",
    "\n",
    "        # C = Slow input-to-hidden weights [shape (4608, 64)]\n",
    "        self.C = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            name=\"inputweights\",\n",
    "            initializer=self.C_initializer,\n",
    "        )\n",
    "        \n",
    "        # W_h The previous hidden state via the slow transition weights [shape (units, units)]\n",
    "        # they suggest to multiply it with 0.05, so gain = 0.05\n",
    "        self.W_h = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            name=\"hiddenweights\",\n",
    "            initializer=self.W_h_initializer, \n",
    "        )\n",
    "        self.W_h = tf.scalar_mul(0.05, self.W_h)\n",
    "        \n",
    "        # A (fast weights) [shape (batch_size, units, units)]\n",
    "        self.A = self.add_weight(\n",
    "            shape=(self.batch, self.units, self.units),\n",
    "            name=\"fastweights\",\n",
    "            initializer=self.A_initializer,\n",
    "        )\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                shape=(self.units,), name=\"bias\", initializer=self.b_x_initializer,\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs, states, training=None):\n",
    "        prev_output = states[0] if nest.is_sequence(states) else states\n",
    "        \n",
    "        # Next hidden state h(t+1) is computed in two steps:\n",
    "        # Step 1 calculate preliminary vector: h_0(t+1) = f(W_h ⋅ h(t) + C ⋅ x(t))\n",
    "        h = K.dot(prev_output, self.W_h) + K.dot(inputs, self.C)\n",
    "        if self.bias is not None:\n",
    "            h = h + self.bias\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        \n",
    "        # Reshape h to use with a\n",
    "        h_s = tf.reshape(h, [self.batch, 1, self.units])\n",
    "        \n",
    "        # Define preliminary vector in variable\n",
    "        prelim = tf.reshape(K.dot(prev_output, self.W_h), (h_s.shape)) + tf.reshape(K.dot(inputs, self.C), (h_s.shape))\n",
    "        \n",
    "        # Fast weights update rule: A(t) = λ*A(t-1) + η*h(t) ⋅ h(t)^T\n",
    "        self.A.assign(\n",
    "            tf.math.add(\n",
    "                tf.scalar_mul(self.l, self.A),\n",
    "                tf.scalar_mul(\n",
    "                    self.e, tf.linalg.matmul(tf.transpose(h_s, [0, 2, 1]), h_s)\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Step 2: Initiate inner loop with preliminary vector, which runs for S steps\n",
    "        # to progressively change the hidden state into h(t+1) = h_s(t+1)\n",
    "        # h_s+1(t+1) f([W_h ⋅ h(t) + C ⋅ x(t)]) + A(t)h_s(t+1)\n",
    "        for _ in range(self.step):\n",
    "            h_s = tf.math.add(prelim, tf.linalg.matmul(h_s, self.A)) \n",
    "#             if self.bias is not None:\n",
    "#                 h_s = h_s + self.bias\n",
    "            if self.activation is not None:\n",
    "                h_s = self.activation(h_s)\n",
    "            \n",
    "            # Apply layer normalization on hidden state\n",
    "            h_s = self.LN(h_s)\n",
    "\n",
    "        h = tf.reshape(h_s, [self.batch, self.units])\n",
    "\n",
    "        output = h\n",
    "        new_state = [output] if nest.is_sequence(states) else output\n",
    "        return output, new_state\n",
    "\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return _generate_zero_filled_state_for_cell(self, inputs, batch_size, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T11:03:55.000148Z",
     "iopub.status.busy": "2020-11-25T11:03:55.000148Z",
     "iopub.status.idle": "2020-11-25T11:03:55.017146Z",
     "shell.execute_reply": "2020-11-25T11:03:55.014148Z",
     "shell.execute_reply.started": "2020-11-25T11:03:55.000148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build model with sequential api\n",
    "def build_model(batch, units, activation_function):\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(seq_train_features.shape[1], seq_train_features.shape[2])))\n",
    "    model.add(\n",
    "        layers.RNN(\n",
    "            FW_RNNCell(units=units, \n",
    "                       use_bias=True, \n",
    "                       activation=activation_function, \n",
    "                       step=1,\n",
    "                       decay_rate = 0.95,\n",
    "                       learning_rate = 0.5,\n",
    "                       batch_size=batch,\n",
    "                   ),\n",
    "            return_sequences=True,\n",
    "            name = 'FW-RNN'\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(7, activation=\"softmax\", name=\"Dense_Output\"))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=[\"accuracy\", 'AUC'],\n",
    "        run_eagerly=False,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T11:06:36.090050Z",
     "iopub.status.busy": "2020-11-25T11:06:36.090050Z",
     "iopub.status.idle": "2020-11-25T11:06:36.219049Z",
     "shell.execute_reply": "2020-11-25T11:06:36.218048Z",
     "shell.execute_reply.started": "2020-11-25T11:06:36.090050Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-6-c6a38c9c0dda>:113 call  *\n        h_s = self.LN(h_s)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1007 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py:1299 call\n        outputs = outputs * math_ops.cast(scale, outputs.dtype)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1180 binary_op_wrapper\n        raise e\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1496 _mul_dispatch\n        return multiply(x, y, name=name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:518 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6077 mul\n        \"Mul\", x=x, y=y, name=name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:592 _create_op_internal\n        compute_device)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3536 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2016 __init__\n        control_input_ops, op_def)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 64 and 32 for '{{node FW-RNN/fw_rnn_cell_1/layer_normalization/mul_3}} = Mul[T=DT_FLOAT](FW-RNN/fw_rnn_cell_1/layer_normalization/Reshape_1, FW-RNN/fw_rnn_cell_1/layer_normalization/mul_3/ReadVariableOp)' with input shapes: [32,1,64], [32].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f8b03d82035d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mseq_val_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfw_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfw_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-9cf8485dc307>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(batch, units, activation_function)\u001b[0m\n\u001b[0;32m     14\u001b[0m                    ),\n\u001b[0;32m     15\u001b[0m             \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'FW-RNN'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         )\n\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    221\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    945\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 947\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[1;32m-> 1086\u001b[1;33m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    856\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m         zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4347\u001b[0m     \u001b[1;31m# the value is discarded.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4348\u001b[0m     output_time_zero, _ = step_function(\n\u001b[1;32m-> 4349\u001b[1;33m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[0;32m   4350\u001b[0m     output_ta = tuple(\n\u001b[0;32m   4351\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(inputs, states)\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_tf_rnn_cell\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell_call_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m           \u001b[0mnew_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1006\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1007\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-6-c6a38c9c0dda>:113 call  *\n        h_s = self.LN(h_s)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1007 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py:1299 call\n        outputs = outputs * math_ops.cast(scale, outputs.dtype)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1180 binary_op_wrapper\n        raise e\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1496 _mul_dispatch\n        return multiply(x, y, name=name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:518 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6077 mul\n        \"Mul\", x=x, y=y, name=name)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:592 _create_op_internal\n        compute_device)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3536 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2016 __init__\n        control_input_ops, op_def)\n    C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 64 and 32 for '{{node FW-RNN/fw_rnn_cell_1/layer_normalization/mul_3}} = Mul[T=DT_FLOAT](FW-RNN/fw_rnn_cell_1/layer_normalization/Reshape_1, FW-RNN/fw_rnn_cell_1/layer_normalization/mul_3/ReadVariableOp)' with input shapes: [32,1,64], [32].\n"
     ]
    }
   ],
   "source": [
    "batchsize = 32\n",
    "a = (seq_train_features.shape[0] // batchsize) * batchsize\n",
    "b = (seq_val_features.shape[0] // batchsize) * batchsize\n",
    "\n",
    "fw_rnn = build_model(batchsize, 64, \"relu\")\n",
    "fw_rnn.summary()\n",
    "\n",
    "# Access tensorboard in cmd of the main repo folder with following code:\n",
    "# tensorboard --logdir='logs/'\n",
    "# name = \"FW-RNN_1layer_{}units_adam_{}_identitymatrix0.05\".format(num_units, act)\n",
    "# tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "\n",
    "# Set callbacks for model training\n",
    "#     csvlog = tf.keras.callbacks.CSVLogger(\n",
    "#         \"data/models/FW-RNN_performance.csv\", separator=\",\", append=False\n",
    "#     )\n",
    "\n",
    "history_best = fw_rnn.fit(\n",
    "    seq_train_features[:a],\n",
    "    seq_train_labels[:a],\n",
    "    batch_size=batchsize,\n",
    "    sample_weight=train_samples_weights[:a],\n",
    "    validation_data=(seq_val_features[:b], seq_val_labels[:b],),\n",
    "    callbacks=[\n",
    "        #                 csvlog,\n",
    "#         tb_callback\n",
    "    ],\n",
    "    epochs=150,\n",
    "    verbose=2,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:52:02.327863Z",
     "iopub.status.busy": "2020-11-21T19:52:02.327863Z",
     "iopub.status.idle": "2020-11-21T19:52:02.333863Z",
     "shell.execute_reply": "2020-11-21T19:52:02.333863Z",
     "shell.execute_reply.started": "2020-11-21T19:52:02.327863Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# for train, test in kfold.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
