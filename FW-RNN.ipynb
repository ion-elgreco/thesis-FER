{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T21:43:42.515702Z",
     "iopub.status.busy": "2020-11-05T21:43:42.515702Z",
     "iopub.status.idle": "2020-11-05T21:43:44.487699Z",
     "shell.execute_reply": "2020-11-05T21:43:44.487699Z",
     "shell.execute_reply.started": "2020-11-05T21:43:42.515702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "Tensorflow Version: 2.4.0-rc0\n",
      "Numpy Version: 1.19.2\n",
      "Keras Version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "# Check if Tensorflow uses GPU\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Limit GPU memory usage\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "print()\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T14:49:39.545616Z",
     "iopub.status.busy": "2020-11-05T14:49:39.545616Z",
     "iopub.status.idle": "2020-11-05T14:49:39.554615Z",
     "shell.execute_reply": "2020-11-05T14:49:39.554615Z",
     "shell.execute_reply.started": "2020-11-05T14:49:39.545616Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(inp_shape):\n",
    "    model = Sequential(name=\"FW-RNN\")\n",
    "\n",
    "    model.add(layers.Dense(7, activation=\"softmax\", name=\"Dense_Output\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T14:49:09.689249Z",
     "iopub.status.busy": "2020-11-05T14:49:09.689249Z",
     "iopub.status.idle": "2020-11-05T14:49:09.912873Z",
     "shell.execute_reply": "2020-11-05T14:49:09.912873Z",
     "shell.execute_reply.started": "2020-11-05T14:49:09.689249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN-LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (LSTM)                (None, 1, 16)             1152      \n",
      "_________________________________________________________________\n",
      "Dense_Output (Dense)         (None, 1, 7)              119       \n",
      "=================================================================\n",
      "Total params: 1,271\n",
      "Trainable params: 1,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_rnn_LSTM = build_model((1, 1))\n",
    "cnn_rnn_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AW2_norm_minitrain = AW2_norm_minitrain.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "history = cnn_rnn_LSTM.fit(\n",
    "    AW2_norm_train.batch(32, drop_remainder=True),\n",
    "    validation_data=AW2_norm_val.batch(32, drop_remainder=True),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_rnn_LSTM.evaluate(AW2_norm_train.batch(8, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T21:26:38.779491Z",
     "iopub.status.busy": "2020-11-05T21:26:38.778492Z",
     "iopub.status.idle": "2020-11-05T21:26:38.791493Z",
     "shell.execute_reply": "2020-11-05T21:26:38.790491Z",
     "shell.execute_reply.started": "2020-11-05T21:26:38.779491Z"
    }
   },
   "source": [
    "# Predict on test set\n",
    "1. Create loop which reads feature_data from each video directory\n",
    "2. Predict on these features\n",
    "3. Write predictions to filename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
