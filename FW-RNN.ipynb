{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:34:49.216769Z",
     "iopub.status.busy": "2020-11-11T16:34:49.215768Z",
     "iopub.status.idle": "2020-11-11T16:34:49.229770Z",
     "shell.execute_reply": "2020-11-11T16:34:49.229770Z",
     "shell.execute_reply.started": "2020-11-11T16:34:49.216769Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from functions import f1, plot_history, arr_replacevalue\n",
    "\n",
    "# Import from features, labels and reshaper function\n",
    "from load_features import (\n",
    "    train_features,\n",
    "    val_features,\n",
    "    train_labels,\n",
    "    val_labels,\n",
    "    features_reshaper,\n",
    "    labels_reshaper\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Limit GPU memory usage\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:34:51.241591Z",
     "iopub.status.busy": "2020-11-11T16:34:51.241591Z",
     "iopub.status.idle": "2020-11-11T16:35:51.986438Z",
     "shell.execute_reply": "2020-11-11T16:35:51.969437Z",
     "shell.execute_reply.started": "2020-11-11T16:34:51.241591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape data to specified sequence length\n",
    "length = 60\n",
    "seq_train_features = features_reshaper(train_features, length)\n",
    "seq_val_features = features_reshaper(val_features, length)\n",
    "# seq_test_features = features_reshaper(test_features, length)\n",
    "\n",
    "seq_train_labels = labels_reshaper(train_labels, length)\n",
    "seq_val_labels = labels_reshaper(val_labels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:35:52.017439Z",
     "iopub.status.busy": "2020-11-11T16:35:52.015440Z",
     "iopub.status.idle": "2020-11-11T16:35:52.757439Z",
     "shell.execute_reply": "2020-11-11T16:35:52.756437Z",
     "shell.execute_reply.started": "2020-11-11T16:35:52.017439Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4 5 6], y=[0 0 0 ... 6 6 6] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot encoded labels back to label integers\n",
    "label_ints = np.argmax(seq_train_labels, axis=2)\n",
    "\n",
    "# Compute class weights with sklearn\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", np.unique(label_ints), label_ints.flatten()\n",
    ")\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Copy label integer array\n",
    "arr = label_ints.copy()\n",
    "\n",
    "# Pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample\n",
    "samples_weights = arr_replacevalue(arr, d_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T12:32:51.580486Z",
     "iopub.status.busy": "2020-11-11T12:32:51.580486Z",
     "iopub.status.idle": "2020-11-11T12:32:51.598489Z",
     "shell.execute_reply": "2020-11-11T12:32:51.597488Z",
     "shell.execute_reply.started": "2020-11-11T12:32:51.580486Z"
    }
   },
   "source": [
    "## Possibilities for custom FW-RNN building\n",
    "-  Build a class fw_layer first to define the inner computation block\n",
    "-  Build the FW-RNN model class to define the outer model (which will be trained)\n",
    "\n",
    "**Best option:\n",
    "-  Build custom FW_RNN cell and wrap it in RNN(FW_RNN)\n",
    "    -  The cell abstraction, together with the generic keras.layers.RNN class, make it very easy to implement custom RNN architectures for your research.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class fw_layer(layers.Layer):\n",
    "#     def __init__(\n",
    "#         self, units=32, input_shape=(params.sequence_dim, params.features_dim)\n",
    "#     ):\n",
    "#         # A layer encapsulates both a state (the layer's \"weights\")\n",
    "#         super(fw_layers, self)\n",
    "#         # Define weight initializers of input weights and input biases\n",
    "#         W_init = tf.keras.initializers.GlorotUniform()\n",
    "#         b_init = tf.keras.initializers.zeros()\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         #         a transformation from inputs to outputs (a \"call\", the layer's forward pass)\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class fw_model(tf.keras.Model):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(CustomModel, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         x = self."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T15:27:37.993463Z",
     "iopub.status.busy": "2020-11-11T15:27:37.993463Z",
     "iopub.status.idle": "2020-11-11T15:27:38.000462Z",
     "shell.execute_reply": "2020-11-11T15:27:38.000462Z",
     "shell.execute_reply.started": "2020-11-11T15:27:37.993463Z"
    }
   },
   "source": [
    "# Create FW-RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:35:56.751441Z",
     "iopub.status.busy": "2020-11-11T16:35:56.751441Z",
     "iopub.status.idle": "2020-11-11T16:35:56.833439Z",
     "shell.execute_reply": "2020-11-11T16:35:56.832437Z",
     "shell.execute_reply.started": "2020-11-11T16:35:56.751441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.python.distribute import distribution_strategy_context as ds_context\n",
    "# from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.keras import activations, initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
    "from tensorflow.python.keras.saving.saved_model import layer_serialization\n",
    "from tensorflow.python.keras.utils import control_flow_util\n",
    "from tensorflow.python.keras.utils import generic_utils\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.training.tracking import base as trackable\n",
    "from tensorflow.python.training.tracking import data_structures\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from tensorflow.tools.docs import doc_controls\n",
    "\n",
    "ops.executing_eagerly_outside_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:35:57.273439Z",
     "iopub.status.busy": "2020-11-11T16:35:57.273439Z",
     "iopub.status.idle": "2020-11-11T16:35:57.299437Z",
     "shell.execute_reply": "2020-11-11T16:35:57.299437Z",
     "shell.execute_reply.started": "2020-11-11T16:35:57.273439Z"
    }
   },
   "outputs": [],
   "source": [
    "def _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):\n",
    "    if inputs is not None:\n",
    "        batch_size = array_ops.shape(inputs)[0]\n",
    "        dtype = inputs.dtype\n",
    "    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n",
    "\n",
    "def _generate_zero_filled_state(batch_size_tensor, state_size, dtype):\n",
    "    \"\"\"Generate a zero filled tensor with shape [batch_size, state_size].\"\"\"\n",
    "    if batch_size_tensor is None or dtype is None:\n",
    "        raise ValueError(\n",
    "            'batch_size and dtype cannot be None while constructing initial state: '\n",
    "            'batch_size={}, dtype={}'.format(batch_size_tensor, dtype))\n",
    "\n",
    "    def create_zeros(unnested_state_size):\n",
    "        flat_dims = tensor_shape.TensorShape(unnested_state_size).as_list()\n",
    "        init_state_size = [batch_size_tensor] + flat_dims\n",
    "        return array_ops.zeros(init_state_size, dtype=dtype)\n",
    "\n",
    "    if nest.is_nested(state_size):\n",
    "        return nest.map_structure(create_zeros, state_size)\n",
    "    else:\n",
    "        return create_zeros(state_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:35:57.750439Z",
     "iopub.status.busy": "2020-11-11T16:35:57.749439Z",
     "iopub.status.idle": "2020-11-11T16:35:57.784437Z",
     "shell.execute_reply": "2020-11-11T16:35:57.784437Z",
     "shell.execute_reply.started": "2020-11-11T16:35:57.750439Z"
    }
   },
   "outputs": [],
   "source": [
    "class FW_RNNCell(layers.Layer):\n",
    "    def __init__(self, units, use_bias, activation, step, **kwargs):\n",
    "        super(FW_RNNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.step = step\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "        self.state_size = self.units\n",
    "        self.output_size = self.units\n",
    "\n",
    "        # Initializer for the kernel weights matrix, used for the linear transformation of the inputs\n",
    "        self.kernel_initializer = initializers.get(\"glorot_uniform\")\n",
    "\n",
    "        # Initializer for the bias vector.\n",
    "        self.bias_initializer = initializers.get(\"zeros\")\n",
    "\n",
    "        # Initializer for the recurrent_kernel (hidden) weights matrix, used for the linear\n",
    "        # transformation of the recurrent state.\n",
    "        self.recurrent_initializer = initializers.get(\"identity\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            name=\"kernel\",\n",
    "            initializer=self.kernel_initializer,\n",
    "        )\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            name=\"recurrent_kernel\",\n",
    "            initializer=self.recurrent_initializer,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                shape=(self.units,), name=\"bias\", initializer=self.bias_initializer,\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        prev_output = states[0] if nest.is_sequence(states) else states\n",
    "\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        if self.bias is not None:\n",
    "            h = K.bias_add(h, self.bias)\n",
    "\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "\n",
    "        new_state = [output] if nest.is_sequence(states) else output\n",
    "        return output, new_state\n",
    "\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return _generate_zero_filled_state_for_cell(self, inputs, batch_size, dtype)\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = {\n",
    "#             \"units\": self.units,\n",
    "#             \"activation\": activations.serialize(self.activation),\n",
    "#             \"use_bias\": self.use_bias,\n",
    "#             \"kernel_initializer\": initializers.serialize(self.kernel_initializer),\n",
    "#             \"recurrent_initializer\": initializers.serialize(self.recurrent_initializer),\n",
    "#         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:43:23.599891Z",
     "iopub.status.busy": "2020-11-11T16:43:23.598892Z",
     "iopub.status.idle": "2020-11-11T16:43:23.609891Z",
     "shell.execute_reply": "2020-11-11T16:43:23.609891Z",
     "shell.execute_reply.started": "2020-11-11T16:43:23.599891Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    model = Sequential(name=\"FW-RNN\")\n",
    "    model.add(layers.InputLayer(input_shape= (seq_train_features.shape[1], seq_train_features.shape[2])))\n",
    "    model.add(\n",
    "        layers.RNN(\n",
    "            FW_RNNCell(units=32, use_bias=True, activation=\"tanh\", step=1),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(7, activation=\"softmax\", name=\"Dense_Output\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adagrad\",\n",
    "        loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=[\"accuracy\", f1, \"AUC\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:43:24.252336Z",
     "iopub.status.busy": "2020-11-11T16:43:24.252336Z",
     "iopub.status.idle": "2020-11-11T16:43:24.331334Z",
     "shell.execute_reply": "2020-11-11T16:43:24.331334Z",
     "shell.execute_reply.started": "2020-11-11T16:43:24.252336Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FW-RNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_2 (RNN)                  (None, 60, 32)            148512    \n",
      "_________________________________________________________________\n",
      "Dense_Output (Dense)         (None, 60, 7)             231       \n",
      "=================================================================\n",
      "Total params: 148,743\n",
      "Trainable params: 148,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fw_rnn = build_model()\n",
    "fw_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T16:43:26.906895Z",
     "iopub.status.busy": "2020-11-11T16:43:26.906895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "481/481 [==============================] - 39s 76ms/step - loss: 1.9682 - accuracy: 0.2812 - f1: 0.0845 - auc: 0.6827 - val_loss: 1.9765 - val_accuracy: 0.2496 - val_f1: 0.0266 - val_auc: 0.6251\n",
      "Epoch 2/10\n",
      "481/481 [==============================] - 35s 72ms/step - loss: 1.5770 - accuracy: 0.3474 - f1: 0.1135 - auc: 0.7462 - val_loss: 1.9545 - val_accuracy: 0.2656 - val_f1: 0.0367 - val_auc: 0.6424\n",
      "Epoch 3/10\n",
      "374/481 [======================>.......] - ETA: 6s - loss: 1.4616 - accuracy: 0.4001 - f1: 0.1590 - auc: 0.7848"
     ]
    }
   ],
   "source": [
    "# AW2_norm_minitrain = AW2_norm_minitrain.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "history_best = fw_rnn.fit(\n",
    "    seq_train_features,\n",
    "    seq_train_labels,\n",
    "    sample_weight=samples_weights,\n",
    "    validation_data=(seq_val_features, seq_val_labels),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T21:26:38.779491Z",
     "iopub.status.busy": "2020-11-05T21:26:38.778492Z",
     "iopub.status.idle": "2020-11-05T21:26:38.791493Z",
     "shell.execute_reply": "2020-11-05T21:26:38.790491Z",
     "shell.execute_reply.started": "2020-11-05T21:26:38.779491Z"
    }
   },
   "source": [
    "# Predict on test set\n",
    "1. Create loop which reads feature_data from each video directory\n",
    "2. Predict on these features\n",
    "3. Write predictions to filename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
