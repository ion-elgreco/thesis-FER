{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:19:48.258577Z",
     "iopub.status.busy": "2020-11-09T15:19:48.254578Z",
     "iopub.status.idle": "2020-11-09T15:19:48.367579Z",
     "shell.execute_reply": "2020-11-09T15:19:48.366578Z",
     "shell.execute_reply.started": "2020-11-09T15:19:48.257577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "Tensorflow Version: 2.4.0-rc0\n",
      "Numpy Version: 1.19.2\n",
      "Keras Version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "# Import from features, labels and reshaper function\n",
    "from load_features import (\n",
    "    train_features,\n",
    "    val_features,\n",
    "    train_labels,\n",
    "    val_labels,\n",
    "    reshaper,\n",
    ")\n",
    "\n",
    "from functions import f1, plot_history, arr_replacevalue\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check if Tensorflow uses GPU\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Limit GPU memory usage\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "print()\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:10:51.481493Z",
     "iopub.status.busy": "2020-11-09T15:10:51.481493Z",
     "iopub.status.idle": "2020-11-09T15:12:02.620491Z",
     "shell.execute_reply": "2020-11-09T15:12:02.600490Z",
     "shell.execute_reply.started": "2020-11-09T15:10:51.481493Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape data to sequence length 150\n",
    "seq_train_features, seq_train_labels = reshaper(train_features, train_labels, 150)\n",
    "seq_val_features, seq_val_labels = reshaper(val_features, val_labels, 150)\n",
    "\n",
    "inp_shape = (seq_train_features.shape[1], seq_train_features.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:12:15.152491Z",
     "iopub.status.busy": "2020-11-09T15:12:15.137491Z",
     "iopub.status.idle": "2020-11-09T15:12:16.901492Z",
     "shell.execute_reply": "2020-11-09T15:12:16.898495Z",
     "shell.execute_reply.started": "2020-11-09T15:12:15.151491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ion\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4 5 6], y=[0 0 0 ... 6 6 6] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot encoded labels back to label integers\n",
    "label_ints = np.argmax(seq_train_labels, axis=2)\n",
    "\n",
    "# Compute class weights with sklearn\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", np.unique(label_ints), label_ints.flatten()\n",
    ")\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Copy label integer array\n",
    "arr = label_ints.copy()\n",
    "\n",
    "# Pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample\n",
    "samples_weights = arr_replacevalue(arr, d_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:19:03.965440Z",
     "iopub.status.busy": "2020-11-09T15:19:03.961439Z",
     "iopub.status.idle": "2020-11-09T15:19:03.999440Z",
     "shell.execute_reply": "2020-11-09T15:19:03.997439Z",
     "shell.execute_reply.started": "2020-11-09T15:19:03.965440Z"
    }
   },
   "outputs": [],
   "source": [
    "class parameters():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_dim = 150\n",
    "        self.num_classes = 7\n",
    "        self.num_epochs = 1000\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.num_hidden_units = 50\n",
    "        self.l = 0.95 # decay lambda\n",
    "        self.e = 0.5 # learning rate eta\n",
    "        self.S = 1 # num steps to get to h_S(t+1)\n",
    "        self.learning_rate = 1e-4\n",
    "        self.learning_rate_decay_factor = 0.99 # don't use this decay\n",
    "        self.max_gradient_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:26:36.368452Z",
     "iopub.status.busy": "2020-11-09T15:26:36.367451Z",
     "iopub.status.idle": "2020-11-09T15:26:36.408450Z",
     "shell.execute_reply": "2020-11-09T15:26:36.408450Z",
     "shell.execute_reply.started": "2020-11-09T15:26:36.368452Z"
    }
   },
   "outputs": [],
   "source": [
    "class FW_RNN(object):\n",
    "\n",
    "    def __init__(self, FLAGS):\n",
    "\n",
    "        self.X = tf.keras.Input(tf.float32,\n",
    "            shape=(None, 150, 4608))\n",
    "        self.y = tf.keras.Input(tf.float32,\n",
    "            shape=(None, 150, 7))\n",
    "        self.l = tf.keras.Input(tf.float32, [], # need [] for tf.scalar_mul\n",
    "            name=\"learning_rate\")\n",
    "        self.e = tf.keras.Input(tf.float32, [],\n",
    "            name=\"decay_rate\")\n",
    "\n",
    "        with tf.variable_scope(\"fast_weights\"):\n",
    "\n",
    "            # input weights (proper initialization)\n",
    "            self.W_x = tf.Variable(tf.random_uniform(\n",
    "                [FLAGS.num_classes, FLAGS.num_hidden_units],\n",
    "                -np.sqrt(2.0/FLAGS.num_classes),\n",
    "                np.sqrt(2.0/FLAGS.num_classes)),\n",
    "                dtype=tf.float32)\n",
    "            self.b_x = tf.Variable(tf.zeros(\n",
    "                [FLAGS.num_hidden_units]),\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            # hidden weights (See Hinton's video @ 21:20)\n",
    "            self.W_h = tf.Variable(\n",
    "                initial_value=0.05 * np.identity(FLAGS.num_hidden_units),\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            # softmax weights (proper initialization)\n",
    "            self.W_softmax = tf.Variable(tf.random_uniform(\n",
    "                [FLAGS.num_hidden_units, FLAGS.num_classes],\n",
    "                -np.sqrt(2.0 / FLAGS.num_hidden_units),\n",
    "                np.sqrt(2.0 / FLAGS.num_hidden_units)),\n",
    "                dtype=tf.float32)\n",
    "            self.b_softmax = tf.Variable(tf.zeros(\n",
    "                [FLAGS.num_classes]),\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            # scale and shift for layernorm\n",
    "            self.gain = tf.Variable(tf.ones(\n",
    "                [FLAGS.num_hidden_units]),\n",
    "                dtype=tf.float32)\n",
    "            self.bias = tf.Variable(tf.zeros(\n",
    "                [FLAGS.num_hidden_units]),\n",
    "                dtype=tf.float32)\n",
    "\n",
    "        # fast weights and hidden state initialization\n",
    "        self.A = tf.zeros(\n",
    "            [FLAGS.batch_size, FLAGS.num_hidden_units, FLAGS.num_hidden_units],\n",
    "            dtype=tf.float32)\n",
    "        self.h = tf.zeros(\n",
    "            [FLAGS.batch_size, FLAGS.num_hidden_units],\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        # NOTE:inputs are batch-major\n",
    "        # Process batch by time-major\n",
    "        for t in range(0, FLAGS.input_dim):\n",
    "\n",
    "            # hidden state (preliminary vector)\n",
    "            self.h = tf.nn.relu((tf.matmul(self.X[:, t, :], self.W_x)+self.b_x) +\n",
    "                (tf.matmul(self.h, self.W_h)))\n",
    "\n",
    "            # Forward weight and layer normalization\n",
    "            if FLAGS.model_name == 'RNN-LN-FW':\n",
    "\n",
    "                # Reshape h to use with a\n",
    "                self.h_s = tf.reshape(self.h,\n",
    "                    [FLAGS.batch_size, 1, FLAGS.num_hidden_units])\n",
    "\n",
    "                # Create the fixed A for this time step\n",
    "                self.A = tf.add(tf.scalar_mul(self.l, self.A),\n",
    "                    tf.scalar_mul(self.e, tf.batch_matmul(tf.transpose(\n",
    "                        self.h_s, [0, 2, 1]), self.h_s)))\n",
    "\n",
    "                # Loop for S steps\n",
    "                for _ in range(FLAGS.S):\n",
    "                    self.h_s = tf.reshape(\n",
    "                        tf.matmul(self.X[:, t, :], self.W_x)+self.b_x,\n",
    "                        tf.shape(self.h_s)) + tf.reshape(\n",
    "                        tf.matmul(self.h, self.W_h), tf.shape(self.h_s)) + \\\n",
    "                        tf.batch_matmul(self.h_s, self.A)\n",
    "\n",
    "                    # Apply layernorm\n",
    "                    mu = tf.reduce_mean(self.h_s, reduction_indices=2) # each sample\n",
    "                    sigma = tf.sqrt(tf.reduce_mean(tf.square(self.h_s - mu),\n",
    "                        reduction_indices=2))\n",
    "                    self.h_s = tf.div(tf.mul(self.gain, (self.h_s - mu)), sigma) + \\\n",
    "                        self.bias\n",
    "\n",
    "                    # Apply nonlinearity\n",
    "                    self.h_s = tf.nn.relu(self.h_s)\n",
    "\n",
    "                # Reshape h_s into h\n",
    "                self.h = tf.reshape(self.h_s,\n",
    "                    [FLAGS.batch_size, FLAGS.num_hidden_units])\n",
    "\n",
    "            elif FLAGS.model_name == 'RNN-LN': # no fast weights but still LN\n",
    "\n",
    "                # Apply layer norm\n",
    "                with tf.variable_scope('just_ln') as scope:\n",
    "                    if t > 0:\n",
    "                        scope.reuse_variables()\n",
    "                    self.h = ln(self.h, scope='h/')\n",
    "\n",
    "            elif FLAGS.model_name == 'CONTROL': # no fast weights or LN\n",
    "                pass\n",
    "\n",
    "        # All inputs processed! Time for softmax\n",
    "        self.logits = tf.matmul(self.h, self.W_softmax) + self.b_softmax\n",
    "\n",
    "        # Loss\n",
    "        self.loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(self.logits, self.y))\n",
    "\n",
    "        # Optimization\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        self.trainable_vars = tf.trainable_variables()\n",
    "        # clip the gradient to avoid vanishing or blowing up gradients\n",
    "        self.grads, self.norm = tf.clip_by_global_norm(\n",
    "            tf.gradients(self.loss, self.trainable_vars), FLAGS.max_gradient_norm)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.update = optimizer.apply_gradients(\n",
    "            zip(self.grads, self.trainable_vars))\n",
    "\n",
    "        # Accuracy\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.logits, 1),\n",
    "            tf.argmax(self.y, 1)), tf.float32))\n",
    "\n",
    "        # Components for model saving\n",
    "        self.global_step = tf.Variable(0, trainable=False) # won't step\n",
    "        self.saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    def step(self, sess, batch_X, batch_y, l, e, forward_only=True):\n",
    "        \"\"\"\n",
    "        Get results for training/validation.\n",
    "        \"\"\"\n",
    "        input_feed = {self.X: batch_X, self.y: batch_y, self.l:l, self.e:e}\n",
    "\n",
    "        if not forward_only: # training\n",
    "            output_feed = [self.loss, self.accuracy, self.norm,\n",
    "            self.update]\n",
    "        elif forward_only: # validation\n",
    "            output_feed = [self.loss, self.accuracy]\n",
    "\n",
    "        # process outputs\n",
    "        outputs = sess.run(output_feed, input_feed)\n",
    "\n",
    "        if not forward_only:\n",
    "            return outputs[0], outputs[1], outputs[2], outputs[3]\n",
    "        elif forward_only:\n",
    "            return outputs[0], outputs[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:26:36.870454Z",
     "iopub.status.busy": "2020-11-09T15:26:36.869453Z",
     "iopub.status.idle": "2020-11-09T15:26:36.883451Z",
     "shell.execute_reply": "2020-11-09T15:26:36.883451Z",
     "shell.execute_reply.started": "2020-11-09T15:26:36.870454Z"
    }
   },
   "outputs": [],
   "source": [
    "FLAGS = parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:26:37.267452Z",
     "iopub.status.busy": "2020-11-09T15:26:37.267452Z",
     "iopub.status.idle": "2020-11-09T15:26:37.278458Z",
     "shell.execute_reply": "2020-11-09T15:26:37.277461Z",
     "shell.execute_reply.started": "2020-11-09T15:26:37.267452Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(inp_shape):\n",
    "    model = Sequential(name=\"FW-RNN\")\n",
    "    model.add(layers.InputLayer(input_shape=inp_shape))\n",
    "    model.add(FW_RNN(FLAGS))\n",
    "    model.add(layers.Dense(7, activation=\"softmax\", name=\"Dense_Output\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T15:26:37.667454Z",
     "iopub.status.busy": "2020-11-09T15:26:37.667454Z",
     "iopub.status.idle": "2020-11-09T15:26:37.705452Z",
     "shell.execute_reply": "2020-11-09T15:26:37.704452Z",
     "shell.execute_reply.started": "2020-11-09T15:26:37.667454Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input() got multiple values for argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-5faee21f941e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_FWrnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcnn_FWrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-f3851b3dffbf>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(inp_shape)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"FW-RNN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minp_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFW_RNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Dense_Output\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-3f4eb0e1b4ae>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, FLAGS)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         self.X = tf.keras.Input(tf.float32,\n\u001b[1;32m----> 6\u001b[1;33m             shape=(None, 150, 4608))\n\u001b[0m\u001b[0;32m      7\u001b[0m         self.y = tf.keras.Input(tf.float32,\n\u001b[0;32m      8\u001b[0m             shape=(None, 150, 7))\n",
      "\u001b[1;31mTypeError\u001b[0m: Input() got multiple values for argument 'shape'"
     ]
    }
   ],
   "source": [
    "cnn_FWrnn = build_model(inp_shape)\n",
    "cnn_FWrnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AW2_norm_minitrain = AW2_norm_minitrain.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "history_best = cnn_FWrnn.fit(\n",
    "    seq_train_features,\n",
    "    seq_train_labels,\n",
    "    sample_weight=samples_weights,\n",
    "    validation_data=(seq_val_features, seq_val_labels),\n",
    "    epochs=150,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T21:26:38.779491Z",
     "iopub.status.busy": "2020-11-05T21:26:38.778492Z",
     "iopub.status.idle": "2020-11-05T21:26:38.791493Z",
     "shell.execute_reply": "2020-11-05T21:26:38.790491Z",
     "shell.execute_reply.started": "2020-11-05T21:26:38.779491Z"
    }
   },
   "source": [
    "# Predict on test set\n",
    "1. Create loop which reads feature_data from each video directory\n",
    "2. Predict on these features\n",
    "3. Write predictions to filename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
