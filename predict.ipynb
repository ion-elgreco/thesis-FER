{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T20:45:29.672187Z",
     "iopub.status.busy": "2020-11-11T20:45:29.671188Z",
     "iopub.status.idle": "2020-11-11T20:45:29.679188Z",
     "shell.execute_reply": "2020-11-11T20:45:29.678187Z",
     "shell.execute_reply.started": "2020-11-11T20:45:29.671188Z"
    }
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "# Import variables and functions from my own scripts\n",
    "from functions import f1\n",
    "from load_features_RGB import (\n",
    "    test_features_AW2,\n",
    "    features_reshaper,\n",
    ")\n",
    "\n",
    "# Limit GPU memory usage\n",
    "for device in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function which writes the predictions to text files for each video\n",
    "def write_predictions(test_filenames, test_pred, video_shapes, path):\n",
    "    # Puts all test_video_names from test set in list\n",
    "    test_videos = []\n",
    "    for fn in test_filenames:\n",
    "        video, frame_n = fn.split(\"\\\\\")\n",
    "        test_videos.append(video)\n",
    "    test_videos = list(set(test_videos))\n",
    "\n",
    "    # Create text file for each video with first line set to all classes in text\n",
    "    for video in test_videos:\n",
    "        with open(join(path, video + \".txt\"), \"w\") as fp:\n",
    "            fp.write(\"Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise\")\n",
    "\n",
    "            \n",
    "    previous_video = \"\"\n",
    "    previous_frame_n = -1\n",
    "    current_frame_n = 0\n",
    "    \n",
    "    def prev_video_append():\n",
    "        # Function to append missing frames at the end of previous video\n",
    "        fullvideo = previous_video.replace(\"_left\", \"\").replace(\"_right\", \"\")\n",
    "        video_length = video_shapes.get(fullvideo)\n",
    "        video_length = video_length[0]\n",
    "\n",
    "        print(f\"Previous video: {previous_video}, diff: {video_length - previous_frame_n}\")\n",
    "\n",
    "        if previous_frame_n != video_length:\n",
    "            diff = video_length - previous_frame_n\n",
    "            with open(\n",
    "                join(path, previous_video + \".txt\"), \"a\"\n",
    "            ) as fp:\n",
    "                for i in range(diff):\n",
    "                    fp.write(\"\\n\" + \"-1\")\n",
    "    \n",
    "\n",
    "    for fn, label in zip(test_filenames, test_pred):\n",
    "        # Convert label to string\n",
    "        label = str(label)\n",
    "\n",
    "        # Split filename into videoname and frame_n\n",
    "        video, frame_n = fn.split(\"\\\\\")\n",
    "        frame_n = int(frame_n.strip(\".jpg\"))\n",
    "\n",
    "        previous_frame_n = current_frame_n\n",
    "        current_frame_n = frame_n\n",
    "\n",
    "        # If we moved to the next video, check if the previous videos frame_n was\n",
    "        # equal to the total amount of frames of the video. If it wasn't, write to\n",
    "        # all the missing lines -1\n",
    "        if previous_video != video:\n",
    "            if previous_video != \"\":\n",
    "                prev_video_append()\n",
    "            previous_video = video\n",
    "            previous_frame_n = 0\n",
    "            \n",
    "        # Calculate difference between current frame_n and previous one\n",
    "        diff = current_frame_n - previous_frame_n\n",
    "\n",
    "        # If frame difference is only 1, then simply write the label on the next line\n",
    "        if diff == 1:\n",
    "            with open(join(path, video + \".txt\"), \"a\") as fp:\n",
    "                fp.write(\"\\n\" + label)\n",
    "        # If the frame difference is larger than 1, simply fill the missing lines with -1, and then write the label\n",
    "        else:\n",
    "            with open(join(path, video + \".txt\"), \"a\") as fp:\n",
    "                for i in range(diff - 1):\n",
    "                    fp.write(\"\\n\" + \"-1\")\n",
    "                fp.write(\"\\n\" + label)\n",
    "    \n",
    "    # Append last video\n",
    "    previous_frame_n = current_frame_n\n",
    "    prev_video_append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape features in sequences and load filenames and videoshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 60\n",
    "seq_test_features = features_reshaper(test_features_AW2, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test set frames filenames\n",
    "with open(\"data/filenames/test_filenames_RGB_AW2.txt\", \"r\") as fp:\n",
    "    test_filenames = fp.read().splitlines()\n",
    "\n",
    "# Read AW2 video shapes to grab the length of each video\n",
    "with open(\"data/AW2_video_shapes_woext.json\", \"r\") as fp:\n",
    "    AW2_video_shapes = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAW2_div = (seq_test_features.shape[0] // batchsize) * batchsize\n",
    "\n",
    "# Load NN\n",
    "for num_units in [5, 20, 50, 100]:\n",
    "    for model in [\"RNN\", \"LSTM\", \"FWRNN\"]:\n",
    "        NN = tf.keras.models.load_model(\n",
    "            filepath=f\"data/models/models_with_extractedfeatures_vgg19block5/{model}_{num_units}units.h5\",\n",
    "            custom_objects={\"F1-metric\": f1},\n",
    "            compile=False,\n",
    "        )\n",
    "        # Predict on Aff-Wild2 Test set\n",
    "        # Do predictions on test set\n",
    "        test_pred_AW2 = NN.predict(seq_test_features[:testAW2_div], verbose=0)\n",
    "\n",
    "        # Reshape back to (frame, label)\n",
    "        test_pred_AW2 = np.reshape(\n",
    "            test_pred_AW2, (test_pred_AW2.shape[0] * test_pred_AW2.shape[1], test_pred_AW2.shape[2])\n",
    "        )\n",
    "\n",
    "        # Convert one hot encoding to integers\n",
    "        test_pred_AW2 = np.argmax(test_pred_AW2, axis=1)\n",
    "\n",
    "        # Run write_predictions function for test set predictions with LSTM model\n",
    "        \n",
    "        predict_dir = r'C:\\Users\\ion\\OneDrive\\Master Data Science and Society\\Blok 1 & 2 - Masterthesis\\Thesis-FER Repo\\data\\AW2_test_preds'\n",
    "        try:\n",
    "            mkdir(join(predict_dir, f'{model}_{num_units}units'))\n",
    "        except FileExistsError:\n",
    "            print(\"Directory already exists!\")\n",
    "        write_predictions(test_filenames[:testAW2_div], test_pred_AW2, AW2_video_shapes, f\"data/AW2_test_preds/{model}_{num_units}units/\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
