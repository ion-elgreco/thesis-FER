{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T20:45:29.672187Z",
     "iopub.status.busy": "2020-11-11T20:45:29.671188Z",
     "iopub.status.idle": "2020-11-11T20:45:29.679188Z",
     "shell.execute_reply": "2020-11-11T20:45:29.678187Z",
     "shell.execute_reply.started": "2020-11-11T20:45:29.671188Z"
    }
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T20:47:04.350109Z",
     "iopub.status.busy": "2020-11-11T20:47:04.349108Z",
     "iopub.status.idle": "2020-11-11T20:47:26.010590Z",
     "shell.execute_reply": "2020-11-11T20:47:26.010590Z",
     "shell.execute_reply.started": "2020-11-11T20:47:04.350109Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join, splitext, normpath\n",
    "\n",
    "# Import variables and functions from my own scripts\n",
    "from functions import f1\n",
    "from load_features import (\n",
    "    test_features_AW2,\n",
    "    features_reshaper,\n",
    ")\n",
    "\n",
    "# Limit GPU memory usage\n",
    "for device in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T20:49:50.254773Z",
     "iopub.status.busy": "2020-11-11T20:49:50.254773Z",
     "iopub.status.idle": "2020-11-11T20:49:50.267772Z",
     "shell.execute_reply": "2020-11-11T20:49:50.267772Z",
     "shell.execute_reply.started": "2020-11-11T20:49:50.254773Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function which writes the predictions to text files for each video\n",
    "def write_predictions(test_filenames, test_pred, video_shapes, model):\n",
    "    if model == 'LSTM':\n",
    "        path = \"data/test_preds_LSTM/\"\n",
    "    elif model == 'FW-RNN':\n",
    "        path = \"data/test_preds_FW-RNN/\"\n",
    "    \n",
    "    # Puts all test_video_names from test set in list\n",
    "    test_videos = []\n",
    "    for fn in test_filenames:\n",
    "        video, frame_n = fn.split(\"\\\\\")\n",
    "        test_videos.append(video)\n",
    "    test_videos = list(set(test_videos))\n",
    "\n",
    "    # Create text file for each video with first line set to all classes in text\n",
    "    for video in test_videos:\n",
    "        with open(join(path, video + \".txt\"), \"w\") as fp:\n",
    "            fp.write(\"Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise\")\n",
    "\n",
    "    current_video = \"\"\n",
    "    previous_frame_n = -1\n",
    "    current_frame_n = 0\n",
    "\n",
    "\n",
    "    for fn, label in zip(test_filenames, test_pred):\n",
    "        # Convert label to string\n",
    "        label = str(label)\n",
    "\n",
    "        # Split filename into videoname and frame_n\n",
    "        video, frame_n = fn.split(\"\\\\\")\n",
    "        frame_n = int(frame_n.strip(\".jpg\"))\n",
    "\n",
    "        previous_frame_n = current_frame_n\n",
    "        current_frame_n = frame_n\n",
    "\n",
    "        # If we moved to the next video, check if the previous videos frame_n was\n",
    "        # equal to the total amount of frames of the video. If it wasn't, write to\n",
    "        # all the missing lines -1\n",
    "        if current_video != video:\n",
    "            if current_video != \"\":\n",
    "                fullvideo = current_video.replace(\"_left\", \"\").replace(\"_right\", \"\")\n",
    "                video_length = video_shapes.get(fullvideo)\n",
    "                video_length = video_length[0]\n",
    "\n",
    "                print(\n",
    "                    f\"Current video: {current_video}, diff: {video_length - previous_frame_n}\"\n",
    "                )\n",
    "\n",
    "                if previous_frame_n != video_length:\n",
    "                    diff = video_length - previous_frame_n\n",
    "                    with open(\n",
    "                        join(path, current_video + \".txt\"), \"a\"\n",
    "                    ) as fp:\n",
    "                        for i in range(diff):\n",
    "                            fp.write(\"\\n\" + \"-1\")\n",
    "            current_video = video\n",
    "            previous_frame_n = 0\n",
    "\n",
    "        # Calculate difference between current frame_n and previous one\n",
    "        diff = current_frame_n - previous_frame_n\n",
    "\n",
    "        # If frame difference is only 1, then simply write the label on the next line\n",
    "        if diff == 1:\n",
    "            with open(join(path, video + \".txt\"), \"a\") as fp:\n",
    "                fp.write(\"\\n\" + label)\n",
    "        # If the frame difference is larger than 1, simply fill the missing lines with -1, and then write the label\n",
    "        else:\n",
    "            with open(join(path, video + \".txt\"), \"a\") as fp:\n",
    "                for i in range(diff - 1):\n",
    "                    fp.write(\"\\n\" + \"-1\")\n",
    "                fp.write(\"\\n\" + label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape features in sequences and load filenames and videoshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 60\n",
    "seq_test_features = features_reshaper(test_features_AW2, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test set frames filenames\n",
    "with open(\"data/test_filenames.txt\", \"r\") as fp:\n",
    "    test_filenames = fp.read().splitlines()\n",
    "\n",
    "# Read AW2 video shapes to grab the length of each video\n",
    "with open(\"data/AW2_video_shapes_woext.json\", \"r\") as fp:\n",
    "    AW2_video_shapes = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T20:49:42.280624Z",
     "iopub.status.busy": "2020-11-11T20:49:42.279626Z",
     "iopub.status.idle": "2020-11-11T20:49:48.578365Z",
     "shell.execute_reply": "2020-11-11T20:49:48.578365Z",
     "shell.execute_reply.started": "2020-11-11T20:49:42.280624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load best LSTM model\n",
    "best_LSTM = tf.keras.models.load_model(\n",
    "    filepath=\"data/LSTM v3/CNN-LSTM_modelv3.h5\", custom_objects={\"F1-metric\": f1}, compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions on test set\n",
    "test_pred_LSTM = best_LSTM.predict(seq_test_features, verbose=0)\n",
    "\n",
    "# Reshape back to (frame, label)\n",
    "test_pred_LSTM = np.reshape(\n",
    "    test_pred_LSTM, (test_pred_LSTM.shape[0] * test_pred_LSTM.shape[1], test_pred_LSTM.shape[2])\n",
    ")\n",
    "\n",
    "# Convert one hot encoding to integers\n",
    "test_pred_LSTM = np.argmax(test_pred_LSTM, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run write_predictions function for test set predictions with LSTM model\n",
    "write_predictions(test_filenames, test_pred_LSTM, AW2_video_shapes, 'LSTM'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FW-RNN - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best FW-RNN model\n",
    "best_FWRNN = tf.keras.models.load_model(\n",
    "    filepath=\"data/FW-RNN/FW-RNN_model.h5\", custom_objects={\"F1-metric\": f1}, compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions on test set\n",
    "test_pred_FWRNN = best_FWRNN.predict(seq_test_features, verbose=0)\n",
    "\n",
    "# Reshape back to (frame, label)\n",
    "test_pred_FWRNN = np.reshape(\n",
    "    test_pred_FWRNN, (test_pred_FWRNN.shape[0] * test_pred_FWRNN.shape[1], test_pred_FWRNN.shape[2])\n",
    ")\n",
    "\n",
    "# Convert one hot encoding to integers\n",
    "test_pred_FWRNN = np.argmax(test_pred_FWRNN, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run write_predictions function for test set predictions with LSTM model\n",
    "write_predictions(test_filenames, test_pred_FWRNN, AW2_video_shapes, 'FW-RNN'):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
