{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T20:45:29.672187Z",
     "iopub.status.busy": "2020-11-11T20:45:29.671188Z",
     "iopub.status.idle": "2020-11-11T20:45:29.679188Z",
     "shell.execute_reply": "2020-11-11T20:45:29.678187Z",
     "shell.execute_reply.started": "2020-11-11T20:45:29.671188Z"
    }
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:53:23.680249Z",
     "iopub.status.busy": "2020-11-12T18:53:23.680249Z",
     "iopub.status.idle": "2020-11-12T18:53:46.833933Z",
     "shell.execute_reply": "2020-11-12T18:53:46.832930Z",
     "shell.execute_reply.started": "2020-11-12T18:53:23.680249Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "# Import variables and functions from my own scripts\n",
    "from functions import f1\n",
    "from load_features import (\n",
    "    test_features_AW2,\n",
    "    features_reshaper,\n",
    ")\n",
    "\n",
    "# Limit GPU memory usage\n",
    "for device in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:53:46.834932Z",
     "iopub.status.busy": "2020-11-12T18:53:46.834932Z",
     "iopub.status.idle": "2020-11-12T18:53:46.848933Z",
     "shell.execute_reply": "2020-11-12T18:53:46.848933Z",
     "shell.execute_reply.started": "2020-11-12T18:53:46.834932Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function which writes the predictions to text files for each video\n",
    "def write_predictions(test_filenames, test_pred, video_shapes, model):\n",
    "    # Create path for predictions depending on model\n",
    "    if model == 'LSTM':\n",
    "        path = \"data/AW2_test_preds/LSTM/\"\n",
    "    elif model == 'FW-RNN':\n",
    "        path = \"data/AW2_test_preds/FW-RNN/\"\n",
    "    \n",
    "    # Puts all test_video_names from test set in list\n",
    "    test_videos = []\n",
    "    for fn in test_filenames:\n",
    "        video, frame_n = fn.split(\"\\\\\")\n",
    "        test_videos.append(video)\n",
    "    test_videos = list(set(test_videos))\n",
    "\n",
    "    # Create text file for each video with first line set to all classes in text\n",
    "    for video in test_videos:\n",
    "        with open(join(path, video + \".txt\"), \"w\") as fp:\n",
    "            fp.write(\"Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise\")\n",
    "\n",
    "            \n",
    "    previous_video = \"\"\n",
    "    previous_frame_n = -1\n",
    "    current_frame_n = 0\n",
    "    \n",
    "    def prev_video_append():\n",
    "        # Function to append missing frames at the end of previous video\n",
    "        fullvideo = previous_video.replace(\"_left\", \"\").replace(\"_right\", \"\")\n",
    "        video_length = video_shapes.get(fullvideo)\n",
    "        video_length = video_length[0]\n",
    "\n",
    "        print(f\"Previous video: {previous_video}, diff: {video_length - previous_frame_n}\")\n",
    "\n",
    "        if previous_frame_n != video_length:\n",
    "            diff = video_length - previous_frame_n\n",
    "            with open(\n",
    "                join(path, previous_video + \".txt\"), \"a\"\n",
    "            ) as fp:\n",
    "                for i in range(diff):\n",
    "                    fp.write(\"\\n\" + \"-1\")\n",
    "    \n",
    "\n",
    "    for fn, label in zip(test_filenames, test_pred):\n",
    "        # Convert label to string\n",
    "        label = str(label)\n",
    "\n",
    "        # Split filename into videoname and frame_n\n",
    "        video, frame_n = fn.split(\"\\\\\")\n",
    "        frame_n = int(frame_n.strip(\".jpg\"))\n",
    "\n",
    "        previous_frame_n = current_frame_n\n",
    "        current_frame_n = frame_n\n",
    "\n",
    "        # If we moved to the next video, check if the previous videos frame_n was\n",
    "        # equal to the total amount of frames of the video. If it wasn't, write to\n",
    "        # all the missing lines -1\n",
    "        if previous_video != video:\n",
    "            if previous_video != \"\":\n",
    "                prev_video_append()\n",
    "            previous_video = video\n",
    "            previous_frame_n = 0\n",
    "            \n",
    "        # Calculate difference between current frame_n and previous one\n",
    "        diff = current_frame_n - previous_frame_n\n",
    "\n",
    "        # If frame difference is only 1, then simply write the label on the next line\n",
    "        if diff == 1:\n",
    "            with open(join(path, video + \".txt\"), \"a\") as fp:\n",
    "                fp.write(\"\\n\" + label)\n",
    "        # If the frame difference is larger than 1, simply fill the missing lines with -1, and then write the label\n",
    "        else:\n",
    "            with open(join(path, video + \".txt\"), \"a\") as fp:\n",
    "                for i in range(diff - 1):\n",
    "                    fp.write(\"\\n\" + \"-1\")\n",
    "                fp.write(\"\\n\" + label)\n",
    "    \n",
    "    # Append last video\n",
    "    previous_frame_n = current_frame_n\n",
    "    prev_video_append()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape features in sequences and load filenames and videoshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:53:46.850933Z",
     "iopub.status.busy": "2020-11-12T18:53:46.849931Z",
     "iopub.status.idle": "2020-11-12T18:53:57.888932Z",
     "shell.execute_reply": "2020-11-12T18:53:57.885930Z",
     "shell.execute_reply.started": "2020-11-12T18:53:46.850933Z"
    }
   },
   "outputs": [],
   "source": [
    "length = 120\n",
    "seq_test_features = features_reshaper(test_features_AW2, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:54:20.336218Z",
     "iopub.status.busy": "2020-11-12T18:54:20.336218Z",
     "iopub.status.idle": "2020-11-12T18:54:20.517922Z",
     "shell.execute_reply": "2020-11-12T18:54:20.516920Z",
     "shell.execute_reply.started": "2020-11-12T18:54:20.336218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read test set frames filenames\n",
    "with open(\"data/filenames/test_filenames_AW2.txt\", \"r\") as fp:\n",
    "    test_filenames = fp.read().splitlines()\n",
    "\n",
    "# Read AW2 video shapes to grab the length of each video\n",
    "with open(\"data/AW2_video_shapes_woext.json\", \"r\") as fp:\n",
    "    AW2_video_shapes = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:54:26.046934Z",
     "iopub.status.busy": "2020-11-12T18:54:26.046934Z",
     "iopub.status.idle": "2020-11-12T18:54:31.152932Z",
     "shell.execute_reply": "2020-11-12T18:54:31.152932Z",
     "shell.execute_reply.started": "2020-11-12T18:54:26.046934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load best LSTM model\n",
    "best_LSTM = tf.keras.models.load_model(\n",
    "    filepath=\"data/models/LSTM_model.h5\", custom_objects={\"F1-metric\": f1}, compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:54:31.154935Z",
     "iopub.status.busy": "2020-11-12T18:54:31.153933Z",
     "iopub.status.idle": "2020-11-12T18:54:49.369583Z",
     "shell.execute_reply": "2020-11-12T18:54:49.369583Z",
     "shell.execute_reply.started": "2020-11-12T18:54:31.154935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do predictions on test set\n",
    "test_pred_LSTM = best_LSTM.predict(seq_test_features, verbose=0)\n",
    "\n",
    "# Reshape back to (frame, label)\n",
    "test_pred_LSTM = np.reshape(\n",
    "    test_pred_LSTM, (test_pred_LSTM.shape[0] * test_pred_LSTM.shape[1], test_pred_LSTM.shape[2])\n",
    ")\n",
    "\n",
    "# Convert one hot encoding to integers\n",
    "test_pred_LSTM = np.argmax(test_pred_LSTM, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T18:55:00.494793Z",
     "iopub.status.busy": "2020-11-12T18:55:00.494793Z",
     "iopub.status.idle": "2020-11-12T18:58:39.915045Z",
     "shell.execute_reply": "2020-11-12T18:58:39.915045Z",
     "shell.execute_reply.started": "2020-11-12T18:55:00.494793Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous video: 122-60-1920x1080-5, diff: -1\n",
      "Previous video: 126-30-1080x1920, diff: 0\n",
      "Previous video: 130-25-1280x720_left, diff: -1\n",
      "Previous video: 130-25-1280x720_right, diff: -1\n",
      "Previous video: 134-30-1280x720, diff: 0\n",
      "Previous video: 136-30-1920x1080, diff: 47\n",
      "Previous video: 14-30-1920x1080, diff: -1\n",
      "Previous video: 16-30-1920x1080, diff: -1\n",
      "Previous video: 166, diff: -1\n",
      "Previous video: 167, diff: -1\n",
      "Previous video: 168, diff: -1\n",
      "Previous video: 169, diff: -1\n",
      "Previous video: 171, diff: -1\n",
      "Previous video: 172, diff: -1\n",
      "Previous video: 175, diff: -1\n",
      "Previous video: 176, diff: -1\n",
      "Previous video: 177, diff: -1\n",
      "Previous video: 178, diff: -1\n",
      "Previous video: 179, diff: -1\n",
      "Previous video: 181, diff: -1\n",
      "Previous video: 182, diff: -1\n",
      "Previous video: 183, diff: -1\n",
      "Previous video: 184, diff: -1\n",
      "Previous video: 185, diff: -1\n",
      "Previous video: 186, diff: 3\n",
      "Previous video: 187, diff: -1\n",
      "Previous video: 188, diff: -1\n",
      "Previous video: 189, diff: -1\n",
      "Previous video: 190, diff: -1\n",
      "Previous video: 191, diff: -1\n",
      "Previous video: 192, diff: -1\n",
      "Previous video: 193, diff: -1\n",
      "Previous video: 194, diff: -1\n",
      "Previous video: 195, diff: -1\n",
      "Previous video: 196, diff: -1\n",
      "Previous video: 197, diff: 83\n",
      "Previous video: 199, diff: -1\n",
      "Previous video: 200, diff: -1\n",
      "Previous video: 201, diff: 0\n",
      "Previous video: 202, diff: 0\n",
      "Previous video: 203, diff: -1\n",
      "Previous video: 204, diff: 0\n",
      "Previous video: 206, diff: 1\n",
      "Previous video: 208, diff: 0\n",
      "Previous video: 209, diff: 118\n",
      "Previous video: 210, diff: 0\n",
      "Previous video: 211, diff: 0\n",
      "Previous video: 212, diff: 0\n",
      "Previous video: 213, diff: 0\n",
      "Previous video: 214, diff: 0\n",
      "Previous video: 215, diff: 31\n",
      "Previous video: 216, diff: 0\n",
      "Previous video: 218, diff: 19\n",
      "Previous video: 219, diff: 3\n",
      "Previous video: 220, diff: 0\n",
      "Previous video: 221, diff: 0\n",
      "Previous video: 223, diff: 0\n",
      "Previous video: 224, diff: 93\n",
      "Previous video: 226, diff: 0\n",
      "Previous video: 227, diff: 0\n",
      "Previous video: 228, diff: 0\n",
      "Previous video: 229, diff: -1\n",
      "Previous video: 230, diff: 0\n",
      "Previous video: 231, diff: -1\n",
      "Previous video: 232, diff: 0\n",
      "Previous video: 233, diff: 119\n",
      "Previous video: 234, diff: 0\n",
      "Previous video: 235, diff: -1\n",
      "Previous video: 236, diff: 0\n",
      "Previous video: 237, diff: 0\n",
      "Previous video: 238, diff: -1\n",
      "Previous video: 239, diff: 0\n",
      "Previous video: 240, diff: 0\n",
      "Previous video: 241, diff: 0\n",
      "Previous video: 242, diff: 0\n",
      "Previous video: 243, diff: -1\n",
      "Previous video: 244, diff: 33\n",
      "Previous video: 245, diff: 0\n",
      "Previous video: 246, diff: 0\n",
      "Previous video: 247, diff: 0\n",
      "Previous video: 248, diff: 0\n",
      "Previous video: 249, diff: 0\n",
      "Previous video: 250, diff: 0\n",
      "Previous video: 251, diff: 0\n",
      "Previous video: 252, diff: -1\n",
      "Previous video: 253, diff: -1\n",
      "Previous video: 254, diff: 0\n",
      "Previous video: 255, diff: -1\n",
      "Previous video: 256, diff: 0\n",
      "Previous video: 257, diff: -1\n",
      "Previous video: 258, diff: 0\n",
      "Previous video: 259, diff: 0\n",
      "Previous video: 260, diff: -1\n",
      "Previous video: 261, diff: 0\n",
      "Previous video: 262, diff: 0\n",
      "Previous video: 264, diff: -1\n",
      "Previous video: 265, diff: 0\n",
      "Previous video: 266, diff: 0\n",
      "Previous video: 267, diff: 0\n",
      "Previous video: 268, diff: 0\n",
      "Previous video: 269, diff: 0\n",
      "Previous video: 270, diff: 0\n",
      "Previous video: 271, diff: -1\n",
      "Previous video: 272, diff: 0\n",
      "Previous video: 273, diff: 0\n",
      "Previous video: 274, diff: 0\n",
      "Previous video: 275, diff: 0\n",
      "Previous video: 276, diff: 0\n",
      "Previous video: 277, diff: 0\n",
      "Previous video: 278, diff: -1\n",
      "Previous video: 279, diff: 0\n",
      "Previous video: 280, diff: 0\n",
      "Previous video: 281, diff: 0\n",
      "Previous video: 283, diff: 120\n",
      "Previous video: 284, diff: 0\n",
      "Previous video: 285, diff: 0\n",
      "Previous video: 286, diff: -1\n",
      "Previous video: 287, diff: -1\n",
      "Previous video: 288, diff: 0\n",
      "Previous video: 289, diff: 0\n",
      "Previous video: 290, diff: 3\n",
      "Previous video: 291, diff: -1\n",
      "Previous video: 292, diff: 0\n",
      "Previous video: 293, diff: 0\n",
      "Previous video: 294, diff: 0\n",
      "Previous video: 295, diff: 0\n",
      "Previous video: 296, diff: 0\n",
      "Previous video: 297, diff: 0\n",
      "Previous video: 298, diff: 0\n",
      "Previous video: 299, diff: -1\n",
      "Previous video: 30-30-1920x1080_left, diff: 1020\n",
      "Previous video: 30-30-1920x1080_right, diff: 1020\n",
      "Previous video: 303, diff: 0\n",
      "Previous video: 304, diff: -1\n",
      "Previous video: 305, diff: -1\n",
      "Previous video: 306, diff: -1\n",
      "Previous video: 307, diff: -1\n",
      "Previous video: 308, diff: 0\n",
      "Previous video: 309, diff: 0\n",
      "Previous video: 311, diff: 0\n",
      "Previous video: 312, diff: 17\n",
      "Previous video: 313, diff: -1\n",
      "Previous video: 314, diff: 0\n",
      "Previous video: 315, diff: 0\n",
      "Previous video: 317, diff: 0\n",
      "Previous video: 318, diff: 28\n",
      "Previous video: 319, diff: 0\n",
      "Previous video: 320, diff: 120\n",
      "Previous video: 321, diff: 0\n",
      "Previous video: 322, diff: -1\n",
      "Previous video: 323, diff: 0\n",
      "Previous video: 324, diff: 0\n",
      "Previous video: 40-30-1280x720, diff: -1\n",
      "Previous video: 43-30-406x720, diff: -1\n",
      "Previous video: 49-30-1280x720_left, diff: -1\n",
      "Previous video: 49-30-1280x720_right, diff: -1\n",
      "Previous video: 52-30-1280x720_left, diff: 61\n",
      "Previous video: 52-30-1280x720_right, diff: 61\n",
      "Previous video: 79-30-960x720, diff: -1\n",
      "Previous video: 92-24-1920x1080, diff: -1\n",
      "Previous video: video10_1_left, diff: 7\n",
      "Previous video: video10_1_right, diff: 7\n",
      "Previous video: video11, diff: -1\n",
      "Previous video: video12, diff: -1\n",
      "Previous video: video13, diff: -1\n",
      "Previous video: video14, diff: -1\n",
      "Previous video: video15, diff: -1\n",
      "Previous video: video16, diff: -1\n",
      "Previous video: video17, diff: -1\n",
      "Previous video: video18, diff: -1\n",
      "Previous video: video19, diff: 9\n",
      "Previous video: video20, diff: -1\n",
      "Previous video: video21, diff: 11\n",
      "Previous video: video22, diff: 11\n",
      "Previous video: video23, diff: 6\n",
      "Previous video: video25, diff: -1\n",
      "Previous video: video26, diff: -1\n",
      "Previous video: video27, diff: 8\n",
      "Previous video: video28, diff: -1\n",
      "Previous video: video29_left, diff: 10\n",
      "Previous video: video29_right, diff: 10\n",
      "Previous video: video30, diff: 3\n",
      "Previous video: video32, diff: 17\n",
      "Previous video: video33, diff: 15\n",
      "Previous video: video35, diff: -1\n",
      "Previous video: video36, diff: 7\n",
      "Previous video: video37, diff: 70\n",
      "Previous video: video38, diff: 8\n",
      "Previous video: video39, diff: 7\n",
      "Previous video: video40, diff: -1\n",
      "Previous video: video41, diff: 28\n",
      "Previous video: video42, diff: 9\n",
      "Previous video: video44, diff: 7\n",
      "Previous video: video45_1, diff: -1\n",
      "Previous video: video45_2, diff: -1\n",
      "Previous video: video45_4, diff: -1\n",
      "Previous video: video46, diff: 5\n",
      "Previous video: video49_right, diff: 40\n",
      "Previous video: video51, diff: -1\n",
      "Previous video: video52, diff: 8\n",
      "Previous video: video53, diff: -1\n",
      "Previous video: video54, diff: 0\n",
      "Previous video: video55_left, diff: 9\n",
      "Previous video: video55_right, diff: 9\n",
      "Previous video: video56, diff: 0\n",
      "Previous video: video57, diff: 48\n",
      "Previous video: video59, diff: 0\n",
      "Previous video: video59_right, diff: 0\n",
      "Previous video: video5_left, diff: 8\n",
      "Previous video: video5_right, diff: 8\n",
      "Previous video: video60, diff: 13\n",
      "Previous video: video62, diff: 0\n",
      "Previous video: video64, diff: 0\n",
      "Previous video: video65, diff: -1\n",
      "Previous video: video69, diff: 0\n",
      "Previous video: video70, diff: 7\n",
      "Previous video: video71, diff: 0\n",
      "Previous video: video74_left, diff: 0\n",
      "Previous video: video74_right, diff: 0\n",
      "Previous video: video75, diff: 0\n",
      "Previous video: video76, diff: 115\n",
      "Previous video: video77, diff: 0\n",
      "Previous video: video78, diff: 0\n",
      "Previous video: video80, diff: 0\n",
      "Previous video: video81, diff: 458\n",
      "Previous video: video82, diff: 0\n",
      "Previous video: video83, diff: 0\n",
      "Previous video: video84, diff: 0\n",
      "Previous video: video85, diff: 0\n",
      "Previous video: video86_1, diff: 0\n",
      "Previous video: video86_2, diff: 0\n",
      "Previous video: video86_3, diff: 0\n",
      "Previous video: video87, diff: 14\n",
      "Previous video: video88, diff: 21\n",
      "Previous video: video89, diff: 0\n",
      "Previous video: video9, diff: 21\n",
      "Previous video: video90, diff: 24\n",
      "Previous video: video91, diff: 0\n",
      "Previous video: video92, diff: 59\n",
      "Previous video: video95, diff: 0\n",
      "Previous video: video96, diff: 91\n"
     ]
    }
   ],
   "source": [
    "# Run write_predictions function for test set predictions with LSTM model\n",
    "write_predictions(test_filenames, test_pred_LSTM, AW2_video_shapes, 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FW-RNN - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best FW-RNN model\n",
    "best_FWRNN = tf.keras.models.load_model(\n",
    "    filepath=\"data/models/FW-RNN_model.h5\", custom_objects={\"F1-metric\": f1}, compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions on test set\n",
    "test_pred_FWRNN = best_FWRNN.predict(seq_test_features, verbose=0)\n",
    "\n",
    "# Reshape back to (frame, label)\n",
    "test_pred_FWRNN = np.reshape(\n",
    "    test_pred_FWRNN, (test_pred_FWRNN.shape[0] * test_pred_FWRNN.shape[1], test_pred_FWRNN.shape[2])\n",
    ")\n",
    "\n",
    "# Convert one hot encoding to integers\n",
    "test_pred_FWRNN = np.argmax(test_pred_FWRNN, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run write_predictions function for test set predictions with LSTM model\n",
    "write_predictions(test_filenames, test_pred_FWRNN, AW2_video_shapes, 'FW-RNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
